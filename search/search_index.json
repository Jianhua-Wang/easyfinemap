{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#easyfinemap","title":"easyfinemap","text":"<p>A flexible framework for GWAS fine-mapping</p> <ul> <li>Documentation: https://Jianhua-Wang.github.io/easyfinemap</li> <li>GitHub: https://github.com/Jianhua-Wang/easyfinemap</li> <li>PyPI: https://pypi.org/project/easyfinemap/</li> <li>License: MIT</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Formatting of summary statistics using smunger.</li> <li>Fast extraction of summary statistics for fine-mapping using tabix/bgzip.</li> <li>Checking and formatting of LD reference.</li> <li>Representation of variants using Unique SNP ID.</li> <li>Support for identifying independent loci using three methods: distance, LD clumping, and conditional analysis.</li> <li>Fine-mapping without the need for LD reference.</li> <li>Support for four LD-based fine-mapping tools and function-based fine-mapping.</li> <li>Fine-mapping combined with conditional analysis.</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":""},{"location":"changelog/#047-2025-03-09","title":"[0.4.7] - 2025-03-09","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>fix bugs in finemap failed</li> </ul>"},{"location":"changelog/#045-2024-04-17","title":"[0.4.5] - 2024-04-17","text":""},{"location":"changelog/#added","title":"Added","text":""},{"location":"changelog/#changed","title":"Changed","text":""},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>fix bugs in polyfun+finemap and polyfun+susie</li> </ul>"},{"location":"changelog/#044-2023-11-09","title":"[0.4.4] - 2023-11-09","text":""},{"location":"changelog/#added_1","title":"Added","text":""},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>discard progress bar, because it is not compatible with multiprocessing</li> </ul>"},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>fix bugs in cojo cond</li> </ul>"},{"location":"changelog/#043-2023-10-25","title":"[0.4.3] - 2023-10-25","text":""},{"location":"changelog/#added_2","title":"Added","text":""},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>env add data.table</li> <li>fix inf beta and se in sumstats</li> </ul>"},{"location":"changelog/#fixed_3","title":"Fixed","text":""},{"location":"changelog/#042-2023-10-23","title":"[0.4.2] - 2023-10-23","text":""},{"location":"changelog/#added_3","title":"Added","text":""},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>load sumstat after multiprocessing</li> <li>aviod error when no intersection ldref with input sumstat</li> <li>fix bugs in cojo cond</li> </ul>"},{"location":"changelog/#fixed_4","title":"Fixed","text":""},{"location":"changelog/#041-2023-10-15","title":"[0.4.1] - 2023-10-15","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>docs</li> </ul>"},{"location":"changelog/#changed_4","title":"Changed","text":""},{"location":"changelog/#fixed_5","title":"Fixed","text":""},{"location":"changelog/#040-2023-10-12","title":"[0.4.0] - 2023-10-12","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>docs</li> </ul>"},{"location":"changelog/#changed_5","title":"Changed","text":""},{"location":"changelog/#fixed_6","title":"Fixed","text":""},{"location":"changelog/#039-2023-09-26","title":"[0.3.9] - 2023-09-26","text":""},{"location":"changelog/#added_6","title":"Added","text":""},{"location":"changelog/#changed_6","title":"Changed","text":""},{"location":"changelog/#fixed_7","title":"Fixed","text":"<ul> <li>fix dependency</li> </ul>"},{"location":"changelog/#035-2023-06-13","title":"[0.3.5] - 2023-06-13","text":""},{"location":"changelog/#added_7","title":"Added","text":""},{"location":"changelog/#changed_7","title":"Changed","text":"<ul> <li>fix smunger independency</li> </ul>"},{"location":"changelog/#fixed_8","title":"Fixed","text":""},{"location":"changelog/#034-2023-06-12","title":"[0.3.4] - 2023-06-12","text":""},{"location":"changelog/#added_8","title":"Added","text":""},{"location":"changelog/#changed_8","title":"Changed","text":"<ul> <li>fix bugs in loci by ldblock</li> </ul>"},{"location":"changelog/#fixed_9","title":"Fixed","text":""},{"location":"changelog/#033-2023-06-12","title":"[0.3.3] - 2023-06-12","text":""},{"location":"changelog/#added_9","title":"Added","text":""},{"location":"changelog/#changed_9","title":"Changed","text":"<ul> <li>fix bugs in loci by ldblock</li> </ul>"},{"location":"changelog/#fixed_10","title":"Fixed","text":""},{"location":"changelog/#032-2023-05-25","title":"[0.3.2] - 2023-05-25","text":""},{"location":"changelog/#added_10","title":"Added","text":""},{"location":"changelog/#changed_10","title":"Changed","text":"<ul> <li>remove pathos</li> </ul>"},{"location":"changelog/#fixed_11","title":"Fixed","text":""},{"location":"changelog/#031-2023-05-25","title":"[0.3.1] - 2023-05-25","text":""},{"location":"changelog/#added_11","title":"Added","text":"<ul> <li>locus plot</li> </ul>"},{"location":"changelog/#changed_11","title":"Changed","text":""},{"location":"changelog/#fixed_12","title":"Fixed","text":""},{"location":"changelog/#030-2023-05-24","title":"[0.3.0] - 2023-05-24","text":""},{"location":"changelog/#added_12","title":"Added","text":"<ul> <li>annotate R2 for locus plot</li> </ul>"},{"location":"changelog/#changed_12","title":"Changed","text":""},{"location":"changelog/#fixed_13","title":"Fixed","text":""},{"location":"changelog/#029-2023-05-24","title":"[0.2.9] - 2023-05-24","text":""},{"location":"changelog/#added_13","title":"Added","text":""},{"location":"changelog/#changed_13","title":"Changed","text":"<ul> <li>Speed up susie by using fread</li> </ul>"},{"location":"changelog/#fixed_14","title":"Fixed","text":""},{"location":"changelog/#028-2023-05-23","title":"[0.2.8] - 2023-05-23","text":""},{"location":"changelog/#added_14","title":"Added","text":""},{"location":"changelog/#changed_14","title":"Changed","text":"<ul> <li>Speed up conditional analysis by intersect ldref with input sumstat first</li> </ul>"},{"location":"changelog/#fixed_15","title":"Fixed","text":""},{"location":"changelog/#027-2023-05-20","title":"[0.2.7] - 2023-05-20","text":""},{"location":"changelog/#added_15","title":"Added","text":""},{"location":"changelog/#changed_15","title":"Changed","text":"<ul> <li>Use tabix to load sumstats when finemap</li> </ul>"},{"location":"changelog/#fixed_16","title":"Fixed","text":""},{"location":"changelog/#026-2023-05-19","title":"[0.2.6] - 2023-05-19","text":""},{"location":"changelog/#added_16","title":"Added","text":"<ul> <li>Support polyfun for finemap and susie</li> </ul>"},{"location":"changelog/#changed_16","title":"Changed","text":"<ul> <li>Use the most significant SNP as lead SNP when COJO fails</li> </ul>"},{"location":"changelog/#fixed_17","title":"Fixed","text":""},{"location":"changelog/#025-2023-03-30","title":"[0.2.5] - 2023-03-30","text":""},{"location":"changelog/#added_17","title":"Added","text":"<ul> <li>set the most significant SNP as SNP, if there are no SNPs with P-value \u2264 threshold.</li> </ul>"},{"location":"changelog/#changed_17","title":"Changed","text":""},{"location":"changelog/#fixed_18","title":"Fixed","text":""},{"location":"changelog/#024-2023-03-30","title":"[0.2.4] - 2023-03-30","text":""},{"location":"changelog/#added_18","title":"Added","text":"<ul> <li>support susie</li> </ul>"},{"location":"changelog/#changed_18","title":"Changed","text":""},{"location":"changelog/#fixed_19","title":"Fixed","text":""},{"location":"changelog/#023-2023-03-24","title":"[0.2.3] - 2023-03-24","text":""},{"location":"changelog/#added_19","title":"Added","text":"<ul> <li>suppor using LD blocks as loci boudaries.</li> </ul>"},{"location":"changelog/#changed_19","title":"Changed","text":""},{"location":"changelog/#fixed_20","title":"Fixed","text":""},{"location":"changelog/#022-2023-03-22","title":"[0.2.2] - 2023-03-22","text":""},{"location":"changelog/#added_20","title":"Added","text":""},{"location":"changelog/#changed_20","title":"Changed","text":"<ul> <li>deleted format function</li> </ul>"},{"location":"changelog/#fixed_21","title":"Fixed","text":""},{"location":"changelog/#021-2023-01-10","title":"[0.2.1] - 2023-01-10","text":""},{"location":"changelog/#added_21","title":"Added","text":"<ul> <li>Instruction of installation</li> </ul>"},{"location":"changelog/#changed_21","title":"Changed","text":""},{"location":"changelog/#fixed_22","title":"Fixed","text":"<ul> <li>typo in easyfinemap.py line519</li> </ul>"},{"location":"changelog/#020-2023-01-10","title":"[0.2.0] - 2023-01-10","text":""},{"location":"changelog/#added_22","title":"Added","text":"<ul> <li>add CAVIARBF</li> </ul>"},{"location":"changelog/#changed_22","title":"Changed","text":""},{"location":"changelog/#fixed_23","title":"Fixed","text":""},{"location":"changelog/#014-2023-01-10","title":"[0.1.4] - 2023-01-10","text":""},{"location":"changelog/#added_23","title":"Added","text":"<ul> <li>add PAINTOR</li> </ul>"},{"location":"changelog/#changed_23","title":"Changed","text":""},{"location":"changelog/#fixed_24","title":"Fixed","text":""},{"location":"changelog/#013-2023-01-09","title":"[0.1.3] - 2023-01-09","text":""},{"location":"changelog/#added_24","title":"Added","text":"<ul> <li>output credible sets</li> </ul>"},{"location":"changelog/#changed_24","title":"Changed","text":""},{"location":"changelog/#fixed_25","title":"Fixed","text":""},{"location":"changelog/#012-2023-01-07","title":"[0.1.2] - 2023-01-07","text":""},{"location":"changelog/#added_25","title":"Added","text":"<ul> <li>update summary statistics using cojo-cond</li> <li>make ld matrix using plink --r2</li> <li>fine-mapping tools: FINEMAP</li> </ul>"},{"location":"changelog/#changed_25","title":"Changed","text":""},{"location":"changelog/#fixed_26","title":"Fixed","text":""},{"location":"changelog/#011-2023-01-07","title":"[0.1.1] - 2023-01-07","text":""},{"location":"changelog/#added_26","title":"Added","text":"<ul> <li>add temp dir decorator</li> <li>identify lead SNPs by LD clumping</li> <li>identify lead SNPs by conditional analysis</li> </ul>"},{"location":"changelog/#changed_26","title":"Changed","text":""},{"location":"changelog/#fixed_27","title":"Fixed","text":""},{"location":"changelog/#005-2022-12-26","title":"[0.0.5] - 2022-12-26","text":""},{"location":"changelog/#added_27","title":"Added","text":"<ul> <li>validate GWAS summary statistics</li> </ul>"},{"location":"changelog/#changed_27","title":"Changed","text":""},{"location":"changelog/#fixed_28","title":"Fixed","text":""},{"location":"changelog/#004-2022-12-26","title":"[0.0.4] - 2022-12-26","text":""},{"location":"changelog/#added_28","title":"Added","text":"<ul> <li>prepare and validate LD reference panel</li> </ul>"},{"location":"changelog/#changed_28","title":"Changed","text":""},{"location":"changelog/#fixed_29","title":"Fixed","text":""},{"location":"changelog/#001-2022-12-20","title":"[0.0.1] - 2022-12-20","text":""},{"location":"changelog/#added_29","title":"Added","text":"<ul> <li>merge the overlapped independent loci (optional).</li> </ul>"},{"location":"changelog/#changed_29","title":"Changed","text":""},{"location":"changelog/#fixed_30","title":"Fixed","text":""},{"location":"changelog/#002-2022-12-22","title":"[0.0.2] - 2022-12-22","text":""},{"location":"changelog/#added_30","title":"Added","text":"<ul> <li>identify the independent lead snps by distance only</li> <li>expand the independent lead snps to independent loci by given range.</li> </ul>"},{"location":"changelog/#changed_30","title":"Changed","text":""},{"location":"changelog/#fixed_31","title":"Fixed","text":""},{"location":"changelog/#003-2022-12-22","title":"[0.0.3] - 2022-12-22","text":""},{"location":"changelog/#added_31","title":"Added","text":"<ul> <li>extract LD ref plink bfile and clean it.</li> </ul>"},{"location":"changelog/#changed_31","title":"Changed","text":""},{"location":"changelog/#fixed_32","title":"Fixed","text":""},{"location":"fileformats/","title":"File formats","text":""},{"location":"fileformats/#summary-statistics","title":"Summary Statistics","text":"<p>easyfinemap requires only one input file, which is the GWAS summary statistics file. This file typically does not have a fixed format and is essentially a tabular file where each row corresponds to the information and results of the association analysis for a specific SNP. To facilitate processing and speed up analysis, we have designed a unified format based on tabix. The file should have exactly 10 columns, and CHR and BP should be indexed using tabix.</p> <p>The 10 columns in the file are as follows:</p> <ol> <li>CHR: Chromosome (integer)</li> <li>BP: Base pair position (integer)</li> <li>rsID: rsID of the SNP (string, allows null values)</li> <li>EA: Effective allele (string)</li> <li>NEA: Non-effective allele (string)</li> <li>EAF: Effective allele frequency (float, allows null values)</li> <li>MAF: Minor allele frequency (float, allows null values)</li> <li>BETA: Effect size (float)</li> <li>SE: Standard error (float, non-zero values)</li> <li>P: p-value (positive float)</li> </ol> <p>By following this format and indexing CHR and BP using tabix, you can ensure compatibility and efficient processing of the GWAS summary statistics file with easyfinemap.</p> <p>Users can easily convert summary statistics from other formats into this format using Smunger.</p>"},{"location":"fileformats/#ld-reference-optional","title":"LD reference (Optional)","text":"<p>To perform LD-based fine-mapping, users need to provide individual genotype data to calculate LD. Ideally, these genotypes should be matched to the sample of summary statistics. However, it is common practice to use publicly available reference panels such as 1000 Genomes (1000G). Since easyfinemap uses PLINK v1.9 to calculate LD, the required genotype data format is PLINK's bfile format.</p> <p>Users need to split the genotype data by chromosome and convert it to the PLINK bfile format. Then, they can use the <code>easyfinemap validate-ldref</code> command to format the LD reference.</p>"},{"location":"fine/","title":"Fine-mapping","text":"<p>easyfinemap supports three types of fine-mapping methods: LD-free, LD-based, and function-based. LD-free methods do not require LD information, LD-based methods rely on LD information, and function-based methods require functional annotation information. Below are the specific software supported for each of these three methods in easyfinemap. The principles of these software are not explained here and can be referred to their respective documentation.</p> <ul> <li>LD-free fine-mapping<ul> <li>aBF</li> </ul> </li> <li>LD-based fine-mapping<ul> <li>PAINOR</li> <li>CAVIARBF</li> <li>FINEMAP</li> <li>SuSiE</li> </ul> </li> <li>Function-based fine-mapping<ul> <li>PolyFun + FINEMAP</li> <li>PolyFun + SuSiE</li> </ul> </li> </ul>"},{"location":"fine/#ld-free-fine-mapping","title":"LD-free fine-mapping","text":"<p><pre><code>$ easyfinemap fine-mapping \\\n    -m abf \\\n    --credible-threshold 0.95 \\\n    PH251.txt.gz \\\n    PH251.distance.loci.txt \\\n    PH251.distance.leadsnp.txt \\\n    PH251.abf.txt\n</code></pre> easyfinemap requires four mandatory parameters:</p> <ul> <li>GWAS summary statistics file</li> <li>loci file</li> <li>lead SNPs file</li> <li>output file</li> </ul> <p>The ABF method was referenced from the article by Asimit, J. L. et al. in Eur J Hum Genet (2016).</p> \\[ ABF = \\sqrt{\\frac{se}{se + w^2}}\\exp\\left(\\frac{w^2}{se + w^2}\\left(\\frac{beta^2}{se^2}\\right)/2\\right) \\] <p>where w is variance prior (parameter <code>--var-prior</code>), usually set to 0.15 for quantitative traits and 0.2 for binary traits. the posterior probability of each variant being causal is calculated using the formula: PP(causal) = ABF / sum(all_abfs)</p> <p>Option <code>--credible-threshold</code> is used to specify the credible threshold, which is used to determine the credible set. The default value is 0.95. The credible set is determined by the posterior probability of each variant being causal. The variants with the highest posterior probability are included in the credible set until the sum of the posterior probability of the variants in the credible set is greater than or equal to the credible threshold. Will output all variants if the credible threshold is set to None.</p>"},{"location":"fine/#ld-based-fine-mapping","title":"LD-based fine-mapping","text":"<p><pre><code>$ easyfinemap fine-mapping \\\n    -m finemap \\\n    --ldref ./EUR.valid.chr{chrom} \\\n    --use-ref-eaf \\\n    --credible-threshold 0.95 \\\n    -n 1000 \\\n    ./PH251.txt.gz \\\n    PH251.distance.loci.txt \\\n    PH251.distance.leadsnp.txt \\\n    PH251.abf\n</code></pre> The example mentioned above utilized FINEMAP for fine-mapping, which requires LD information. You can generate LD reference files based on the tutorial provided in the \"Validate LD reference\" section. The easyfinemap tool automatically generates the necessary input files for each loci and retrieves the results.</p> <p>Please note that if the summary statistics do not include EAF (Effect Allele Frequency) information, you need to use the <code>--use-ref-eaf</code> parameter to use the LD reference's EAF as the EAF in order to avoid any errors.</p>"},{"location":"fine/#function-based-fine-mapping","title":"Function-based fine-mapping","text":"<p>Users can also perform fine-mapping using the prior probabilities provided by PolyFun. This method requires users to provide functional annotation information, such as gene expression levels and chromatin states. The specific usage details can be found in the PolyFun documentation.</p> <p>To perform PolyFun's fine-mapping using easyfinemap, it is straightforward. Simply specify the <code>--prior-file</code> parameter in the command line, for example: <pre><code>$ easyfinemap fine-mapping \\\n    -m polyfun_finemap \\\n    --prior-file ./prior.txt \\\n    --credible-threshold 0.95 \\\n    PH251.txt.gz \\\n    PH251.distance.loci.txt \\\n    PH251.distance.leadsnp.txt \\\n    PH251.abf.txt\n</code></pre> Users can utilize the prior probability file provided by PolyFun or generate their own. For specific usage instructions, please refer to the PolyFun documentation.</p> <p>The prior probability file provided by PolyFun is in Parquet format. To facilitate GitHub uploading, it is divided into two files: chr1-7 and chr8-22. Users need to merge these two files into one and then specify the path to this file using the <code>--prior-file</code> parameter.</p> <p>The format is as follows: <pre><code>CHR     BP      SNP     A1      A2      snpvar_bin\n1       10177   rs367896724     A       AC      0.0\n1       10352   rs201106462     T       TA      0.0\n1       10511   rs534229142     G       A       0.0\n1       10616   1:10616_CCGCCGTTGCAAAGGCGCGCCG_C        CCGCCGTTGCAAAGGCGCGCCG  C       0.0\n1       11008   rs575272151     C       G       0.0\n1       11012   rs544419019     C       G       0.0\n1       13110   rs540538026     G       A       0.0\n1       13116   rs62635286      T       G       0.0\n1       13118   rs62028691      A       G       0.0\n</code></pre></p>"},{"location":"fine/#fine-mapping-with-conditional-analysis","title":"Fine-mapping with conditional analysis","text":"<p>If users have used conditional analysis to determine the lead SNP of a locus, they can utilize the <code>--conditional</code> parameter to perform fine-mapping using the results of conditional analysis. For example: <pre><code>$ easyfinemap fine-mapping \\\n    -m finemap \\\n    --credible-threshold 0.95 \\\n    --conditional \\\n    --ldref ./EUR.valid.chr{chrom} \\\n    --use-ref-eaf \\\n    -n 1000 \\\n    PH251.txt.gz \\\n    PH251.conditional.loci.txt \\\n    PH251.conditional.leadsnp.txt \\\n    PH251.abf.txt\n</code></pre> easyfinemap will employ GCTA COJO to perform conditional analysis. For each locus, conditional analysis generates new summary statistics by conditioning on other lead SNPs within a specified interval. This interval is determined by the '--cond-snps-wind-kb' parameter, which has a default value of 10000 (10 Mb).</p>"},{"location":"fine/#fine-mapping-with-multiple-methods","title":"Fine-mapping with multiple methods","text":"<p>In summary, easyfinemap supports multiple fine-mapping methods. Users can specify a single method or multiple methods to perform fine-mapping simultaneously by using multiple <code>-m</code> parameters in the command line. For example: <pre><code>$ easyfinemap fine-mapping \\\n    -m abf -m finemap \\\n    --ldref ./EUR.valid.chr{chrom} \\\n    --use-ref-eaf \\\n    --credible-threshold 0.95 \\\n    --credible-method finemap \\\n    -n 1000 \\\n    ./PH251.txt.gz \\\n    PH251.distance.loci.txt \\\n    PH251.distance.leadsnp.txt \\\n    PH251.abf\n</code></pre> You can also specify <code>-m</code> all to perform fine-mapping using all supported methods. For example: <pre><code>$ easyfinemap fine-mapping \\\n    -m all \\\n    --ldref ./EUR.valid.chr{chrom} \\\n    --use-ref-eaf \\\n    --credible-threshold 0.95 \\\n    --credible-method finemap \\\n    -n 1000 \\\n    ./PH251.txt.gz \\\n    PH251.distance.loci.txt \\\n    PH251.distance.leadsnp.txt \\\n    PH251.abf\n</code></pre> Please note that when using multiple methods for fine-mapping, you need to specify the <code>--credible-method</code> parameter to determine which method should be used to determine the credible set.</p>"},{"location":"fine/#output","title":"Output","text":"<p>The output file is a tab-delimited text file. The first line is the header, which contains the following columns: <pre><code>$ head PH251.finemap.txt\nSNPID   CHR     BP      rsID    EA      NEA     EAF     MAF     BETA    SE      P       PP_FINEMAP      LEAD_SNP\n22-29451671-A-G 22      29451671        rs4823006       G       A                       -0.0241 0.0037  7.99e-11        0.917195        22-29451671-A-G\n22-29449477-A-G 22      29449477        rs2294239       G       A                       -0.0243 0.004   8.26e-10        0.0721721       22-29451671-A-G\n</code></pre> The first 11 columns are the same as the GWAS summary statistics file. The <code>PP_FINEMAP</code> column is the posterior probability of each variant being causal. The <code>LEAD_SNP</code> column is the lead SNP of the locus.</p>"},{"location":"fine/#other-parameters","title":"Other parameters","text":"<p><code>--max-causal</code> parameter is used to specify the maximum number of causal SNPs. The default value is 1.</p> <p><code>--cond-snps-wind-kb</code> parameter is used to specify the conditional SNPs window size, in kb. The default value is 10000.</p> <p><code>--threads</code> parameter is used to specify the number of threads. The default value is 1.</p>"},{"location":"fine/#help-information","title":"Help information","text":"<pre><code>$ easyfinemap fine-mapping -h\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 EasyFinemap \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                                  Version: 0.4.0\n                               Author: Jianhua Wang\n                          Email: jianhua.mert@gmail.com\n\n Usage: easyfinemap fine-mapping [OPTIONS] SUMSTATS_PATH LOCI_PATH\n                                 LEAD_SNPS_PATH OUTFILE\n\n Fine mapping.\n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *    sumstats_path       TEXT  The path to the GWAS summary statistics file.   \u2502\n\u2502                                [default: None]                                 \u2502\n\u2502                                [required]                                      \u2502\n\u2502 *    loci_path           TEXT  The path to the loci file, generated by         \u2502\n\u2502                                get-loci command.                               \u2502\n\u2502                                [default: None]                                 \u2502\n\u2502                                [required]                                      \u2502\n\u2502 *    lead_snps_path      TEXT  The path to the lead SNPs file, generated by    \u2502\n\u2502                                get-loci command.                               \u2502\n\u2502                                [default: None]                                 \u2502\n\u2502                                [required]                                      \u2502\n\u2502 *    outfile             TEXT  The output file. [default: None] [required]     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --methods             -m      [abf|finemap|paintor|  The methods to use.    \u2502\n\u2502                                  caviarbf|susie|polyfu  [default: None]        \u2502\n\u2502                                  n_susie|polyfun_finem  [required]             \u2502\n\u2502                                  ap|all]                                       \u2502\n\u2502    --var-prior                   FLOAT                  The prior variance for \u2502\n\u2502                                                         the aBF method.        \u2502\n\u2502                                                         [default: 0.2]         \u2502\n\u2502    --conditional         -c                             Whether to use         \u2502\n\u2502                                                         conditional mode.      \u2502\n\u2502    --prior-file                  TEXT                   The path to the prior  \u2502\n\u2502                                                         file.                  \u2502\n\u2502                                                         [default: None]        \u2502\n\u2502    --sample-size         -n      INTEGER                The sample size for    \u2502\n\u2502                                                         conditional mode.      \u2502\n\u2502                                                         [default: None]        \u2502\n\u2502    --ldref                       TEXT                   The path to the LD     \u2502\n\u2502                                                         reference file.        \u2502\n\u2502                                                         [default: None]        \u2502\n\u2502    --cond-snps-wind-kb           INTEGER                The conditional SNPs   \u2502\n\u2502                                                         window size, in kb.    \u2502\n\u2502                                                         [default: 10000]       \u2502\n\u2502    --max-causal                  INTEGER                The maximum number of  \u2502\n\u2502                                                         causal SNPs.           \u2502\n\u2502                                                         [default: 1]           \u2502\n\u2502    --credible-threshold          FLOAT                  The credible           \u2502\n\u2502                                                         threshold.             \u2502\n\u2502                                                         [default: None]        \u2502\n\u2502    --credible-method             TEXT                   The fine-mapping       \u2502\n\u2502                                                         method for credible    \u2502\n\u2502                                                         set.                   \u2502\n\u2502                                                         [default: None]        \u2502\n\u2502    --use-ref-eaf                                        Whether to use the     \u2502\n\u2502                                                         reference panel EAF.   \u2502\n\u2502    --threads             -t      INTEGER                The number of threads. \u2502\n\u2502                                                         [default: 1]           \u2502\n\u2502    --help                -h                             Show this message and  \u2502\n\u2502                                                         exit.                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"identify/","title":"Identify independent loci","text":"<p>Because fine-mapping is typically conducted locally, determining the regions for fine-mapping a summary statistic requires identifying the regions based on significant loci in a GWAS.</p> <p>EasyFinemap provides three methods to determine the regions for fine-mapping: distance, clumping, and conditional. </p> <ul> <li>The distance method merges nearby variants within a given distance threshold into a locus and selects a lead SNP from each locus.</li> <li>The clumping method merges variants within the same clumping window based on a specified window size and r2 threshold, and selects a lead SNP from each merged locus.</li> <li>The conditional method merges variants within the same cojo window based on a specified window size and cojo collinear threshold, and selects a lead SNP from each merged locus.</li> </ul> <p>The key difference among these methods lies in the criteria used for merging variants: distance and clumping methods are based on physical distances between variants, while the conditional method is based on their correlation. </p> <p>Both distance and clumping methods utilize GWAS summary statistics, whereas the conditional method incorporates both GWAS summary statistics and LD reference.</p> <p>Here is an example of using EasyFinemap for locus identification:</p> <p>Download the example data (ignore if already downloaded): <pre><code>git clone https://github.com/Jianhua-Wang/easyfinemap.git\ncd easyfinemap/exampledata\nls\n</code></pre> PH251.txt.gz is the GWAS summary statistics file, and PH251.txt.gz.tbi is the tabix index file.</p> <p>PH251.sig.txt.gz is the significant SNPs file which contains the SNPs with p-value less than 5e-08.</p> <p>To expedite the process, you can directly use the \"sig.txt.gz\" file, and the results will be the same as those from \"PH251.sig.txt.gz\".</p>"},{"location":"identify/#by-distance","title":"By distance","text":"<pre><code>$ easyfinemap get-loci -m  distance PH251.sig.txt.gz PH251.distance\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 EasyFinemap \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                                  Version: 0.3.9\n                               Author: Jianhua Wang\n                          Email: jianhua.mert@gmail.com\n[22:33:22] INFO     root - Loading PH251.sig.txt.gz...\n           INFO     Loci - Save 1 independent loci to PH251.distance.loci.txt\n           INFO     Loci - Save 1 independent lead snps to PH251.distance.leadsnp.txt\n</code></pre>"},{"location":"identify/#by-clumping","title":"By clumping","text":"<p><pre><code>$ easyfinemap get-loci -m clumping --ldref ./EUR.valid.chr{chrom} ./PH251.sig.txt.gz PH251.clumping\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 EasyFinemap \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                                  Version: 0.3.9\n                               Author: Jianhua Wang\n                          Email: jianhua.mert@gmail.com\n[22:35:20] INFO     root - Loading PH251.sig.txt.gz...\n           INFO     Loci - Save 1 independent loci to PH251.clumping.loci.txt\n           INFO     Loci - Save 1 independent lead snps to\n                    PH251.clumping.leadsnp.txt\n</code></pre> Other parameters can be specified as follows: <pre><code>--clump-kb: the clumping window size, in kb. Default: 500\n--clump-r2: the clumping r2 threshold. Default: 0.1\n</code></pre></p>"},{"location":"identify/#by-conditional-analysis","title":"By conditional analysis","text":"<p><pre><code>$ easyfinemap get-loci \\\n    -m conditional \\\n    --use-ref-eaf \\\n    -n 40000 \\\n    --ldref ./EUR.valid.chr{chrom} \\\n    PH251.sig.txt.gz \\\n    PH251.conditional\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 EasyFinemap \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                                  Version: 0.3.9\n                               Author: Jianhua Wang\n                          Email: jianhua.mert@gmail.com\n[23:07:54] INFO     root - Loading PH251.sig.txt.gz...\nRun cojo-slct \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1/1 0:00:00\n           INFO     Loci - Save 1 independent loci to PH251.conditional.loci.txt\n           INFO     Loci - Save 1 independent lead snps to\n                    PH251.conditional.leadsnp.txt\n</code></pre> Parameters can be specified as follows: <pre><code>--use-ref-eaf: whether to use the reference panel EAF. Default: False. \nIf True, the reference panel EAF will be used for conditional analysis. \nMust be specified when the EAF is not available in the GWAS summary statistics file.\n\n-n: the sample size for conditional analysis.\n--cojo-window-kb: the cojo window size, in kb. Default: 10000\n--cojo-collinear: the cojo collinear threshold. Default: 0.9\n--diff-freq: the difference in allele frequency threshold. Default: 0.2\n</code></pre></p>"},{"location":"identify/#other-parameters","title":"Other parameters","text":"<pre><code>--sig-threshold: the significance threshold. Default: 5e-08\n--loci-extension: the extension from lead SNPs, in kb. Default: 500\n--ldblock: the path to the LD block file. Default: None, bed file with 3 columns: chr, start, end\n</code></pre>"},{"location":"identify/#output-files","title":"Output files","text":"<p>.leadsnp.txt, contains the lead SNPs for each locus. The first line is the header, and the following lines are the lead SNPs for each locus. The columns are: <pre><code>$ head PH251.clumping.leadsnp.txt\nSNPID   CHR     BP      rsID    EA      NEA     EAF     MAF     BETA    SE      P\n22-29451671-A-G 22      29451671        rs4823006       G       A                       -0.0241 0.0037  7.99e-11\n</code></pre> .loci.txt, contains the loci for each lead SNP. The first line is the header, and the following lines are the loci for each lead SNP. The columns are: <pre><code>$ head PH251.clumping.loci.txt\nCHR     START   END     LEAD_SNP        LEAD_SNP_P      LEAD_SNP_BP\n22      28951671        29951671        22-29451671-A-G 7.99e-11        29451671\n</code></pre></p>"},{"location":"identify/#help-information","title":"Help information","text":"<pre><code>$ easyfinemap get-loci -h\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 EasyFinemap \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                                  Version: 0.3.9\n                               Author: Jianhua Wang\n                          Email: jianhua.mert@gmail.com\n\n Usage: easyfinemap get-loci [OPTIONS] SUMSTATS_PATH OUTPUT\n\n Get the loci from the GWAS summary statistics file.\n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *    sumstats_path      PATH  The path to the GWAS summary statistics file.    \u2502\n\u2502                               [default: None]                                  \u2502\n\u2502                               [required]                                       \u2502\n\u2502 *    output             TEXT  The output prefix. [default: None] [required]    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --sig-threshold      -s      FLOAT                    The significance         \u2502\n\u2502                                                       threshold.               \u2502\n\u2502                                                       [default: 5e-08]         \u2502\n\u2502 --loci-extension     -l      INTEGER                  The extension from lead  \u2502\n\u2502                                                       SNPs, in kb              \u2502\n\u2502                                                       [default: 500]           \u2502\n\u2502 --ldblock                    TEXT                     The path to the LD block \u2502\n\u2502                                                       file.                    \u2502\n\u2502                                                       [default: None]          \u2502\n\u2502 --merge-loci         -i                               Whether to merge the     \u2502\n\u2502                                                       loci, not recommanded    \u2502\n\u2502                                                       for conditional mode.    \u2502\n\u2502 --method             -m      [distance|clumping|cond  The method to identify   \u2502\n\u2502                              itional]                 the lead SNPs.           \u2502\n\u2502                                                       [default:                \u2502\n\u2502                                                       LociMethod.distance]     \u2502\n\u2502 --distance           -d      INTEGER                  The distance threshold   \u2502\n\u2502                                                       for distance method, in  \u2502\n\u2502                                                       kb.                      \u2502\n\u2502                                                       [default: 50]            \u2502\n\u2502 --ldref                      TEXT                     The path to the LD       \u2502\n\u2502                                                       reference file.          \u2502\n\u2502                                                       [default: None]          \u2502\n\u2502 --clump-kb           -c      INTEGER                  The clumping window      \u2502\n\u2502                                                       size, in kb.             \u2502\n\u2502                                                       [default: 500]           \u2502\n\u2502 --clump-r2           -r      FLOAT                    The clumping r2          \u2502\n\u2502                                                       threshold.               \u2502\n\u2502                                                       [default: 0.1]           \u2502\n\u2502 --sample-size        -n      INTEGER                  The sample size for      \u2502\n\u2502                                                       conditional method.      \u2502\n\u2502                                                       [default: None]          \u2502\n\u2502 --cojo-window-kb             INTEGER                  The cojo window size, in \u2502\n\u2502                                                       kb.                      \u2502\n\u2502                                                       [default: 10000]         \u2502\n\u2502 --cojo-collinear             FLOAT                    The cojo collinear       \u2502\n\u2502                                                       threshold.               \u2502\n\u2502                                                       [default: 0.9]           \u2502\n\u2502 --diff-freq                  FLOAT                    The difference in allele \u2502\n\u2502                                                       frequency threshold.     \u2502\n\u2502                                                       [default: 0.2]           \u2502\n\u2502 --use-ref-eaf                                         Whether to use the       \u2502\n\u2502                                                       reference panel EAF.     \u2502\n\u2502 --only-use-sig-snps                                   Whether to only use the  \u2502\n\u2502                                                       significant SNPs.        \u2502\n\u2502 --threads            -t      INTEGER                  The number of threads.   \u2502\n\u2502                                                       [default: 1]             \u2502\n\u2502 --help               -h                               Show this message and    \u2502\n\u2502                                                       exit.                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>easyfinemap is a Python package that can be installed directly using pip. However, since easyfinemap requires additional fine-mapping software to compute posterior probabilities, such as FINEMAP and PAINTOR, you will need to install these software as well. Users have the option to install them manually or clone the easyfinemap conda environment. Here are the specific steps:</p> <ol> <li>Download the environment configuration file:    <pre><code>wget https://raw.githubusercontent.com/Jianhua-Wang/easyfinemap/main/environment.yml\n</code></pre></li> <li>Create a conda environment:    <pre><code>conda env create -f environment.yml\n</code></pre></li> <li>Activate the conda environment:    <pre><code>conda activate easyfinemap\n</code></pre> Once the conda environment is activated, you will have easyfinemap and the required fine-mapping software installed and ready to use.</li> </ol>"},{"location":"quickstart/","title":"Quick start","text":"<p>To perform the simplest fine-mapping using easyfinemap, including determining independent loci using the distance-based method and calculating the posterior probability for each SNP using the abf method, you can follow these steps:</p> <ol> <li> <p>Download the example data (ignore if already downloaded): <pre><code>git clone https://github.com/Jianhua-Wang/easyfinemap.git\ncd easyfinemap/exampledata\n</code></pre></p> </li> <li> <p>Determine independent loci using the distance-based method: <pre><code>$ easyfinemap get-loci -m  distance PH251.sig.txt.gz PH251.distance\n</code></pre></p> </li> <li> <p>Calculate the posterior probability for each SNP using the abf method: <pre><code>$ easyfinemap fine-mapping \\\n    -m abf \\\n    --credible-threshold 0.95 \\\n    PH251.txt.gz \\\n    PH251.distance.loci.txt \\\n    PH251.distance.leadsnp.txt \\\n    PH251.abf.txt\n</code></pre></p> </li> </ol> <p>For more advanced features and parameter explanations, please refer to the documentation\u3002</p>"},{"location":"usage/","title":"Usage","text":"<p>To use easy_finemap in a project</p> <pre><code>import easy_finemap\n</code></pre>"},{"location":"validate/","title":"Validate LD reference","text":"<p>The validation of the LD reference is performed to facilitate the calculation of the LD matrix. However, if you intend to use LD-free fine-mapping methods, you can disregard this step.</p> <p>The <code>validate-ldref</code> method in EasyFinemap quickly validates the PLINK bfile format. The main steps involved are as follows:</p> <ul> <li>If the input is not already separated by chromosome, the PLINK bfile is split by chromosome.</li> <li>Variants with a minor allele count below a specified threshold (default is 10) are filtered out.</li> <li>Multiallelic variants are removed.</li> <li>Duplicate variants are removed.</li> <li>Variant IDs are converted to Unique SNP IDs for easy matching of summary statistics with variants in the LD reference. In EasyFinemap, the Unique SNP ID format used is chr-bp-sorted(EA,NEA).</li> </ul> <p>Let's demonstrate the usage of <code>validate-ldref</code> with an example dataset.</p> <p>Download the example data: <pre><code>git clone https://github.com/Jianhua-Wang/easyfinemap.git\ncd easyfinemap/exampledata\nls\n</code></pre> The exampledata directory contains bfiles with the prefix EUR.chr21 for chromosome 21, EUR.chr22 for chromosome 22, and EUR.chr21-22, which is a merged file of chromosomes 21 and 22.</p> <p><code>validate-ldref</code> supports both split-by-chromosome bfiles (such as those directly converted from chromosome-separated VCF files from 1000 Genomes) and non-split bfiles. The specific command is as follows: <pre><code>easyfinemap validate-ldref ./EUR.chr21-22 EUR.valid\n</code></pre> For split-by-chromosome bfiles, use the {chrom} wildcard to represent the chromosome number. <pre><code>easyfinemap validate-ldref ./EUR.chr{chrom} EUR.valid\n</code></pre> Other parameters:</p> <p><pre><code>$ easyfinemap validate-ldref -h\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 EasyFinemap \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                                  Version: 0.3.9\n                               Author: Jianhua Wang\n                          Email: jianhua.mert@gmail.com\n\n Usage: easyfinemap validate-ldref [OPTIONS] LDREF_PATH OUTPREFIX\n\n Validate the LD reference file.\n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *    ldref_path      TEXT  The path to the LD reference file. [default: None]  \u2502\n\u2502                            [required]                                          \u2502\n\u2502 *    outprefix       TEXT  The output prefix. [default: None] [required]       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --file-type  -f      TEXT     The file type of the LD reference file.          \u2502\n\u2502                               [default: plink]                                 \u2502\n\u2502 --mac        -m      INTEGER  The minor allele count threshold. [default: 10]  \u2502\n\u2502 --threads    -t      INTEGER  The number of threads. [default: 1]              \u2502\n\u2502 --help       -h               Show this message and exit.                      \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> The <code>-m</code> option allows you to change the minor allele count threshold for filtering. It should be set to a value greater than 0 because a minor allele count of 0 can cause errors in LD matrix calculations. The <code>-t</code> option specifies the number of threads. Setting it higher can speed up the process. Parallelization is performed by chromosome, so it should not exceed the total number of chromosomes.</p>"},{"location":"api/LDRef/","title":"LDRef","text":"<p>Prepare LD reference for easyfinemap.</p> Source code in <code>easyfinemap/ldref.py</code> <pre><code>def __init__(self):\n\"\"\"Initialize the LDRef class.\"\"\"\n    self.logger = logging.getLogger(\"LDRef\")\n    self.plink = Tools().plink\n    self.gcta = Tools().gcta\n    self.tmp_root = Path.cwd() / \"tmp\" / \"ldref\"\n    if not self.tmp_root.exists():\n        self.tmp_root.mkdir(parents=True)\n</code></pre>"},{"location":"api/LDRef/#easyfinemap.LDRef.annotate_r2","title":"<code>annotate_r2(sumstat, ldref, ld_snp, temp_dir=None)</code>","text":"<p>Annotate SNPs with r2 to the lead SNP.</p> <p>Parameters:</p> Name Type Description Default <code>sumstat</code> <code>DataFrame</code> <p>The summary statistics.</p> required <code>ldref</code> <code>str</code> <p>The path to the LD reference file.</p> required <code>ld_snp</code> <code>str</code> <p>The lead SNP.</p> required <code>temp_dir</code> <code>Optional[str]</code> <p>The path to the temporary directory, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The annotated summary statistics.</p> Source code in <code>easyfinemap/ldref.py</code> <pre><code>@io_in_tempdir('./tmp/ldref')\ndef annotate_r2(\n    self,\n    sumstat: pd.DataFrame,\n    ldref: str,\n    ld_snp: str,\n    temp_dir: Optional[str] = None,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Annotate SNPs with r2 to the lead SNP.\n\n    Parameters\n    ----------\n    sumstat : pd.DataFrame\n        The summary statistics.\n    ldref : str\n        The path to the LD reference file.\n    ld_snp : str\n        The lead SNP.\n    temp_dir : Optional[str], optional\n        The path to the temporary directory, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        The annotated summary statistics.\n    \"\"\"\n    if len(sumstat[ColName.CHR].unique()) &gt; 1:\n        raise ValueError(\"Only one chromosome is allowed.\")\n    chrom = sumstat[ColName.CHR].iloc[0]\n    if len(sumstat) &gt; 100000:\n        self.logger.warning(\n            \"The sumstats is large, it may take a long time to annotate the r2.\"\n        )\n    ld = LDRef()\n    r2_df = sumstat.copy()\n    r2_input = ld.intersect(sumstat, ldref.format(chrom=chrom), f\"{temp_dir}/r2_input_{chrom}\")\n    if ld_snp not in r2_input[ColName.SNPID].tolist():\n        raise ValueError(f\"{ld_snp} not in the LD reference.\")\n    cmd = [\n        self.plink,\n        \"--bfile\",\n        f\"{temp_dir}/r2_input_{chrom}\",\n        \"--r2\",\n        \"--ld-snp\",\n        ld_snp,\n        \"--ld-window-kb\",\n        \"100000\",\n        \"--ld-window\",\n        \"99999999\",\n        \"--ld-window-r2\",\n        \"0\",\n        \"--keep-allele-order\",\n        \"--out\",\n        f\"{temp_dir}/r2_{chrom}\",\n    ]\n    self.logger.debug(f\"annotate r2: {' '.join(cmd)}\")\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        raise RuntimeError(res.stderr)\n    else:\n        res_r2 = pd.read_csv(f\"{temp_dir}/r2_{chrom}.ld\", delim_whitespace=True)\n        res_r2 = pd.Series(res_r2[\"R2\"].values, index=res_r2[\"SNP_B\"].values)\n        r2_df[\"R2\"] = r2_df[ColName.SNPID].map(res_r2)\n        r2_df.loc[r2_df[ColName.SNPID] == ld_snp, \"R2\"] = 1\n        r2_df['R2'] = r2_df['R2'].fillna(-1)\n        return r2_df\n</code></pre>"},{"location":"api/LDRef/#easyfinemap.LDRef.cojo_cond","title":"<code>cojo_cond(sumstats, cond_snps, ldref, sample_size, use_ref_EAF=False, temp_dir=None)</code>","text":"<p>Conditional analysis. Update the beta, se, pval of the conditional SNPs.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>The summary statistics.</p> required <code>cond_snps</code> <code>DataFrame</code> <p>The conditional SNPs.</p> required <code>ldref</code> <code>str</code> <p>The path to the LD reference file.</p> required <code>sample_size</code> <code>int</code> <p>The sample size.</p> required <code>use_ref_EAF</code> <code>bool</code> <p>Whether to use the EAF in the LD reference file, by default False</p> <code>False</code> <code>temp_dir</code> <code>Optional[str]</code> <p>The path to the temporary directory, by default None</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the EAF is not in the sumstats and use_ref_EAF is False.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The updated summary statistics.</p> Source code in <code>easyfinemap/ldref.py</code> <pre><code>@io_in_tempdir('./tmp/ldref')\ndef cojo_cond(\n    self,\n    sumstats: pd.DataFrame,\n    cond_snps: pd.DataFrame,\n    ldref: str,\n    sample_size: int,\n    use_ref_EAF: bool = False,\n    temp_dir: Optional[str] = None,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Conditional analysis. Update the beta, se, pval of the conditional SNPs.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        The summary statistics.\n    cond_snps : pd.DataFrame\n        The conditional SNPs.\n    ldref : str\n        The path to the LD reference file.\n    sample_size : int\n        The sample size.\n    use_ref_EAF : bool, optional\n        Whether to use the EAF in the LD reference file, by default False\n    temp_dir : Optional[str], optional\n        The path to the temporary directory, by default None\n\n    Raises\n    ------\n    ValueError\n        If the EAF is not in the sumstats and use_ref_EAF is False.\n\n    Returns\n    -------\n    pd.DataFrame\n        The updated summary statistics.\n    \"\"\"\n    if not use_ref_EAF and ColName.EAF not in sumstats.columns:\n        raise ValueError(\n            f\"{ColName.EAF} is not in the sumstats, please set use_ref_EAF to True\"\n        )\n    chrom = sumstats[ColName.CHR].iloc[0]\n    # ld = LDRef()\n    # all_sumstats = pd.concat([sumstats, cond_snps], ignore_index=True)\n    # all_sumstats.drop_duplicates(subset=[ColName.SNPID], inplace=True)\n    # all_sumstats.sort_values(by=[ColName.CHR, ColName.BP], inplace=True)\n    # all_sumstats.reset_index(drop=True, inplace=True)\n    # cojo_input = ld.intersect(all_sumstats, ldref, f\"{temp_dir}/cojo_input_{chrom}\", use_ref_EAF)\n    cojo_input = sumstats.copy()\n    cojo_input[ColName.N] = sample_size\n    cojo_input = cojo_input[\n        [\n            ColName.SNPID,\n            ColName.EA,\n            ColName.NEA,\n            ColName.EAF,\n            ColName.BETA,\n            ColName.SE,\n            ColName.P,\n            ColName.N,\n        ]\n    ]\n    cojo_input.rename(\n        columns={\n            ColName.SNPID: \"SNP\",\n            ColName.EA: \"A1\",\n            ColName.NEA: \"A2\",\n            ColName.EAF: \"freq\",\n            ColName.BETA: \"b\",\n            ColName.SE: \"se\",\n            ColName.P: \"p\",\n            ColName.N: \"N\",\n        },\n        inplace=True,\n    )\n    cojo_p_file = f\"{temp_dir}/cojo_input_{chrom}.ma\"\n    cojo_input.to_csv(cojo_p_file, sep=\" \", index=False)\n    with open(f\"{temp_dir}/cojo_cond_{chrom}.snps\", \"w\") as f:\n        f.write('\\n'.join(cond_snps[ColName.SNPID].tolist()))\n    cojo_outfile = f\"{temp_dir}/cojo_{chrom}.cond\"\n    cmd = [\n        self.gcta,\n        \"--bfile\",\n        ldref,\n        \"--cojo-file\",\n        cojo_p_file,\n        \"--diff-freq\",\n        \"1\",\n        \"--cojo-collinear\",\n        \"0.99\",\n        \"--cojo-cond\",\n        f\"{temp_dir}/cojo_cond_{chrom}.snps\",\n        \"--out\",\n        cojo_outfile,\n    ]\n    self.logger.debug(f\"conditional analysis: {' '.join(cmd)}\")\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    if res.returncode != 0:\n        except_error = 'Error: there is a collinearity problem of the given list of SNPs.'\n        if except_error in res.stdout and os.path.exists(\n            f\"{temp_dir}/cojo_{chrom}.cond.given.cojo\"\n        ):\n            self.logger.warning(\n                'there is a collinearity problem of the given list of SNPs. Try slct again'\n            )\n            cojo_input[cojo_input['SNP'].isin(cond_snps[ColName.SNPID])].to_csv(\n                f\"{temp_dir}/cojo_{chrom}.reslct.ma\", sep=\" \", index=False\n            )\n            cmd = [\n                self.gcta,\n                \"--bfile\",\n                ldref,\n                \"--cojo-file\",\n                f\"{temp_dir}/cojo_{chrom}.reslct.ma\",\n                \"--diff-freq\",\n                \"1\",\n                \"--cojo-collinear\",\n                \"0.9\",\n                \"--cojo-slct\",\n                \"--out\",\n                f\"{temp_dir}/cojo_{chrom}.reslct\",\n            ]\n            self.logger.debug(f\"slct again: {' '.join(cmd)}\")\n            res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n            if res.returncode != 0:\n                self.logger.error(res.stdout)\n                raise RuntimeError(res.stdout)\n            else:\n                new_conds = pd.read_csv(\n                    f\"{temp_dir}/cojo_{chrom}.reslct.jma.cojo\", delim_whitespace=True\n                )\n                new_conds = new_conds[new_conds['pJ'] &lt; 5e-8]['SNP'].values\n                with open(f\"{temp_dir}/cojo_cond_{chrom}.snps\", \"w\") as f:\n                    f.write('\\n'.join(new_conds))\n                cmd = [\n                    self.gcta,\n                    \"--bfile\",\n                    ldref,\n                    \"--cojo-file\",\n                    cojo_p_file,\n                    \"--diff-freq\",\n                    \"1\",\n                    \"--cojo-collinear\",\n                    \"0.99\",\n                    \"--cojo-cond\",\n                    f\"{temp_dir}/cojo_cond_{chrom}.snps\",\n                    \"--out\",\n                    cojo_outfile,\n                ]\n                self.logger.debug(f\"conditional analysis: {' '.join(cmd)}\")\n                res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n                if res.returncode != 0:\n                    self.logger.error(res.stdout)\n                    raise RuntimeError(res.stdout)\n        # self.logger.error(res.stdout)\n        # raise RuntimeError(res.stdout)\n    if os.path.exists(f\"{cojo_outfile}.cma.cojo\"):\n        cond_res = pd.read_csv(\n            f\"{cojo_outfile}.cma.cojo\", sep=\"\\t\", usecols=[\"SNP\", \"bC\", \"bC_se\", \"pC\"]\n        )\n        cond_res.rename(\n            columns={\n                \"SNP\": ColName.SNPID,\n                \"bC\": ColName.COJO_BETA,\n                \"bC_se\": ColName.COJO_SE,\n                \"pC\": ColName.COJO_P,\n            },\n            inplace=True,\n        )\n        output = sumstats.merge(cond_res, on=ColName.SNPID, how=\"left\")\n        output = output.dropna(subset=[ColName.COJO_P, ColName.COJO_BETA, ColName.COJO_SE])\n        return output\n    else:\n        return sumstats\n</code></pre>"},{"location":"api/LDRef/#easyfinemap.LDRef.extract","title":"<code>extract(inprefix, outprefix, chrom, temp_dir=None, start=None, end=None, mac=10)</code>","text":"<p>Extract the genotypes of given region from the LD reference.</p> <p>Parameters:</p> Name Type Description Default <code>inprefix</code> <code>str</code> <p>The input prefix.</p> required <code>outprefix</code> <code>str</code> <p>The output prefix.</p> required <code>chrom</code> <code>int</code> <p>The chromosome number.</p> required <code>temp_dir</code> <code>str</code> <p>The temporary directory.</p> <code>None</code> <code>start</code> <code>int</code> <p>The start position, by default None</p> <code>None</code> <code>end</code> <code>int</code> <p>The end position, by default None</p> <code>None</code> <code>mac</code> <code>int</code> <p>The minor allele count threshold, by default 10</p> <code>10</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>easyfinemap/ldref.py</code> <pre><code>@io_in_tempdir(dir=\"./tmp/ldref\")\ndef extract(\n    self,\n    inprefix: str,\n    outprefix: str,\n    chrom: int,\n    temp_dir: Optional[str] = None,\n    start: Optional[int] = None,\n    end: Optional[int] = None,\n    mac: int = 10,\n) -&gt; None:\n\"\"\"\n    Extract the genotypes of given region from the LD reference.\n\n    Parameters\n    ----------\n    inprefix : str\n        The input prefix.\n    outprefix : str\n        The output prefix.\n    chrom : int\n        The chromosome number.\n    temp_dir : str\n        The temporary directory.\n    start : int, optional\n        The start position, by default None\n    end : int, optional\n        The end position, by default None\n    mac: int, optional\n        The minor allele count threshold, by default 10\n\n    Returns\n    -------\n    None\n    \"\"\"\n    region_file = f\"{temp_dir}/{outprefix.split('/')[-1]}.region\"\n    if start is None:\n        extract_cmd = [\"--chr\", str(chrom)]\n    else:\n        with open(region_file, \"w\") as f:\n            f.write(f\"{chrom}\\t{start}\\t{end}\\tregion\")\n        extract_cmd = [\"--extract\", \"range\", region_file]\n\n    if \"{chrom}\" in inprefix:\n        inprefix = inprefix.replace(\"{chrom}\", str(chrom))\n    if not os.path.exists(f\"{inprefix}.bed\"):\n        raise FileNotFoundError(f\"{inprefix}.bed not found.\")\n    cmd = [\n        self.plink,\n        \"--bfile\",\n        inprefix,\n        *extract_cmd,\n        \"--keep-allele-order\",\n        \"--mac\",\n        str(mac),\n        \"--make-bed\",\n        \"--out\",\n        outprefix,\n    ]\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    self.logger.debug(' '.join(cmd))\n    self.logger.debug(f\"extract chr{chrom}:{start}-{end} from {inprefix}\")\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        self.logger.error(f'see log file: {outprefix}.log for details')\n        raise RuntimeError(res.stderr)\n</code></pre>"},{"location":"api/LDRef/#easyfinemap.LDRef.intersect","title":"<code>intersect(sumstats, ldref, out_plink, use_ref_EAF=False, temp_dir=None)</code>","text":"<p>Intersect the significant snps with the LD reference.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>The summary statistics.</p> required <code>ldref</code> <code>str</code> <p>The path to the LD reference file.</p> required <code>out_plink</code> <code>str</code> <p>The output prefix.</p> required <code>use_ref_EAF</code> <code>bool</code> <p>Use the EAF in the LD reference, by default False</p> <code>False</code> <code>temp_dir</code> <code>Optional[str]</code> <p>The path to the temporary directory, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The intersected significant snps.</p> Source code in <code>easyfinemap/ldref.py</code> <pre><code>@io_in_tempdir(dir=\"./tmp/ldref\")\ndef intersect(\n    self,\n    sumstats: pd.DataFrame,\n    ldref: str,\n    out_plink: str,\n    use_ref_EAF: bool = False,\n    temp_dir: Optional[str] = None,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Intersect the significant snps with the LD reference.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        The summary statistics.\n    ldref : str\n        The path to the LD reference file.\n    out_plink : str\n        The output prefix.\n    use_ref_EAF : bool, optional\n        Use the EAF in the LD reference, by default False\n    temp_dir : Optional[str], optional\n        The path to the temporary directory, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        The intersected significant snps.\n    \"\"\"\n    if not os.path.exists(f\"{ldref}.bim\"):\n        raise FileNotFoundError(f\"{ldref}.bim not found.\")\n    sumstats[ColName.SNPID].to_csv(f\"{temp_dir}/overlap_snpid.txt\", index=False, header=False)\n    cmd = [\n        self.plink,\n        \"--bfile\",\n        ldref,\n        \"--extract\",\n        f\"{temp_dir}/overlap_snpid.txt\",\n        \"--keep-allele-order\",\n        \"--make-bed\",\n        \"--out\",\n        out_plink,\n    ]\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    self.logger.debug(' '.join(cmd))\n    self.logger.debug(f\"intersect {sumstats.shape[0]} SNPs with {ldref}\")\n    if res.returncode != 0:\n        self.logger.warning(res.stderr)\n        self.logger.warning(f'see log file: {out_plink}.log for details')\n        # raise RuntimeError(res.stderr)\n        return pd.DataFrame()\n    else:\n        bim = pd.read_csv(\n            f\"{out_plink}.bim\",\n            delim_whitespace=True,\n            names=[ColName.CHR, ColName.RSID, \"cM\", ColName.BP, ColName.EA, ColName.NEA],\n        )\n        overlap_sumstat = sumstats[sumstats[ColName.SNPID].isin(bim[ColName.RSID])].copy()\n        overlap_sumstat.reset_index(drop=True, inplace=True)\n\n        if use_ref_EAF:\n            cmd = [\n                self.plink,\n                \"--bfile\",\n                out_plink,\n                \"--freq\",\n                \"--out\",\n                f\"{temp_dir}/freq\",\n            ]\n            res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n            self.logger.debug(f\"calculate EAF of {out_plink}\")\n            self.logger.debug(f\"calculate EAF: {' '.join(cmd)}\")\n            # if res.returncode != 0:\n            #     self.logger.error(res.stderr)\n            #     self.logger.error(f'see log file: {temp_dir}/freq.log for details')\n            #     raise RuntimeError(res.stderr)\n            freq = pd.read_csv(f\"{temp_dir}/freq.frq\", delim_whitespace=True)\n            freq['A2_frq'] = 1 - freq['MAF']\n            overlap_sumstat['EAF'] = freq['A2_frq'].where(\n                freq['A2'] == overlap_sumstat['EA'], freq['MAF']\n            )\n            overlap_sumstat['MAF'] = freq['MAF']\n        return overlap_sumstat\n</code></pre>"},{"location":"api/LDRef/#easyfinemap.LDRef.make_ld","title":"<code>make_ld(ldref, outprefix, **kwargs)</code>","text":"<p>Make the LD matrix.</p> <p>TODO: Calculate LD matrix using plink-pandas, because plink1.9 --ld contains bug.</p> <p>Parameters:</p> Name Type Description Default <code>ldref</code> <code>str</code> <p>The path to the LD reference file.</p> required <code>outprefix</code> <code>str</code> <p>The output prefix.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the return code is not 0.</p> <p>Returns:</p> Type Description <code>None</code> Source code in <code>easyfinemap/ldref.py</code> <pre><code>@io_in_tempdir('./tmp/ldref')\ndef make_ld(\n    self,\n    ldref: str,\n    outprefix: str,\n    **kwargs,\n):\n\"\"\"\n    Make the LD matrix.\n\n    TODO: Calculate LD matrix using plink-pandas, because plink1.9 --ld contains bug.\n\n    Parameters\n    ----------\n    ldref : str\n        The path to the LD reference file.\n    outprefix : str\n        The output prefix.\n\n    Raises\n    ------\n    RuntimeError\n        If the return code is not 0.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    self.logger.info(f\"Making LD matrix: {outprefix}\")\n    cmd = [\n        self.plink,\n        \"--bfile\",\n        ldref,\n        \"--r2\",\n        \"square\",\n        \"spaces\",\n        \"--threads\",\n        \"1\",\n        \"--out\",\n        outprefix,\n    ]\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    self.logger.debug(f\"get LD matrix: {' '.join(cmd)}\")\n    if res.returncode != 0:\n        self.logger.warning(res.stderr)\n        self.logger.warning(f'see log file: {outprefix}.log for details')\n    else:\n        self.logger.debug(\"LD matrix is made\")\n        run([\"sed\", \"-i\", \"s/nan/1e-6/g\", f\"{outprefix}.ld\"])\n</code></pre>"},{"location":"api/LDRef/#easyfinemap.LDRef.valid","title":"<code>valid(ldref_path, outprefix, file_type='plink', mac=10, threads=1, temp_dir=None)</code>","text":"<p>Validate the LD reference file.</p> <p>TODO:1. format vcfs to plink files. 2. remove duplicated snps. 3. remove snps with MAC &lt; mac. 4. make SNP names unique, chr-bp-sorted(EA,NEA). TODO:5. mark bim file with \"#easyfinemap validated\" flag in the first line.</p> <p>Parameters:</p> Name Type Description Default <code>ldref_path</code> <code>str</code> <p>The path to the LD reference file.</p> required <code>outprefix</code> <code>str</code> <p>The output prefix.</p> required <code>file_type</code> <code>str</code> <p>The file type of the LD reference file, by default \"plink\"</p> <code>'plink'</code> <code>mac</code> <code>int</code> <p>The minor allele count threshold, by default 10 SNPs with MAC &lt; mac will be removed.</p> <code>10</code> <code>threads</code> <code>int</code> <p>The number of threads to use, by default 1</p> <code>1</code> <code>temp_dir</code> <code>Optional[str]</code> <p>The path to the temporary directory, by default None</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the file type is not supported.</p> <p>Returns:</p> Type Description <code>None</code> Source code in <code>easyfinemap/ldref.py</code> <pre><code>@io_in_tempdir(dir='./tmp/ldref')\ndef valid(\n    self,\n    ldref_path: str,\n    outprefix: str,\n    file_type: str = \"plink\",\n    mac: int = 10,\n    threads: int = 1,\n    temp_dir: Optional[str] = None,\n) -&gt; None:\n\"\"\"\n    Validate the LD reference file.\n\n    TODO:1. format vcfs to plink files.\n    2. remove duplicated snps.\n    3. remove snps with MAC &lt; mac.\n    4. make SNP names unique, chr-bp-sorted(EA,NEA).\n    TODO:5. mark bim file with \"#easyfinemap validated\" flag in the first line.\n\n    Parameters\n    ----------\n    ldref_path : str\n        The path to the LD reference file.\n    outprefix : str\n        The output prefix.\n    file_type : str, optional\n        The file type of the LD reference file, by default \"plink\"\n    mac: int, optional\n        The minor allele count threshold, by default 10\n        SNPs with MAC &lt; mac will be removed.\n    threads : int, optional\n        The number of threads to use, by default 1\n    temp_dir : Optional[str], optional\n        The path to the temporary directory, by default None\n\n    Raises\n    ------\n    ValueError\n        If the file type is not supported.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    if file_type == \"plink\":\n        self.file_type = file_type\n    else:\n        raise ValueError(f\"Unsupported file type: {file_type}\")\n\n    params: List[List[Union[str, int]]] = [[] for _ in range(3)]\n    for chrom in CHROMS:\n        if \"{chrom}\" in ldref_path:\n            inprefix = ldref_path.replace(\"{chrom}\", str(chrom))\n            if not os.path.exists(f\"{inprefix}.bed\"):\n                if chrom == 23:\n                    inprefix = ldref_path.replace(\"{chrom}\", \"X\")\n                    if os.path.exists(f\"{inprefix}.bed\"):\n                        self.logger.warning(f\"chr{chrom} not found, use X instead.\")\n                        params[0].append(inprefix)\n                        params[1].append(f\"{outprefix}.chr{chrom}\")\n                        params[2].append(mac)\n                    else:\n                        self.logger.warning(f\"{inprefix}.bed not found.\")\n                else:\n                    self.logger.warning(f\"{inprefix}.bed not found.\")\n                    continue\n            else:\n                params[0].append(inprefix)\n                params[1].append(f\"{outprefix}.chr{chrom}\")\n                params[2].append(mac)\n        else:\n            inprefix = ldref_path\n            if not os.path.exists(f\"{inprefix}.bed\"):\n                raise FileNotFoundError(f\"{inprefix}.bed not found.\")\n            else:\n                # check if chrom is in the bim file\n                res = check_output(\n                    f'grep \"^{chrom}[[:space:]]\" {inprefix}.bim | head -n 1', shell=True\n                )\n                if len(res.decode()) == 0:\n                    self.logger.warning(f\"Chrom {chrom} not found in {inprefix}.bim\")\n                    continue\n                else:\n                    intermed_prefix = f\"{temp_dir}/{outprefix.split('/')[-1]}.chr{chrom}\"\n                    self.extract(inprefix, intermed_prefix, chrom, mac=mac)\n                    params[0].append(intermed_prefix)\n                    params[1].append(f\"{outprefix}.chr{chrom}\")\n                    params[2].append(mac)\n\n    with Pool(threads) as p:\n        p.map(self._clean_per_chr, *params)\n</code></pre>"},{"location":"api/Loci/","title":"Loci","text":"<p>Identify the independent loci.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>def __init__(self):\n\"\"\"Initialize the Loci class.\"\"\"\n    self.logger = logging.getLogger(\"Loci\")\n    self.plink = Tools().plink\n    self.gcta = Tools().gcta\n    self.tmp_root = Path.cwd() / \"tmp\" / \"loci\"\n    if not self.tmp_root.exists():\n        self.tmp_root.mkdir(parents=True)\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.clump_per_chr","title":"<code>clump_per_chr(sig_df, ldref, clump_p1, clump_kb, clump_r2, temp_dir=None)</code>","text":"<p>LD clumping per chromosome.</p> <p>Parameters:</p> Name Type Description Default <code>sig_df</code> <code>DataFrame</code> <p>The significant snps.</p> required <code>ldref</code> <code>str</code> <p>The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.</p> required <code>clump_p1</code> <code>float</code> <p>The p1 threshold.</p> required <code>clump_kb</code> <code>int</code> <p>The kb threshold.</p> required <code>clump_r2</code> <code>float</code> <p>The r2 threshold.</p> required <code>temp_dir</code> <code>Optional[str]</code> <p>The temporary directory, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The clumped snps.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>@io_in_tempdir(dir=\"./tmp/loci\")\ndef clump_per_chr(\n    self,\n    sig_df: pd.DataFrame,\n    ldref: str,\n    clump_p1: float,\n    clump_kb: int,\n    clump_r2: float,\n    temp_dir: Optional[str] = None,\n) -&gt; pd.DataFrame:\n\"\"\"\n    LD clumping per chromosome.\n\n    Parameters\n    ----------\n    sig_df : pd.DataFrame\n        The significant snps.\n    ldref : str\n        The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.\n    clump_p1 : float\n        The p1 threshold.\n    clump_kb : int\n        The kb threshold.\n    clump_r2 : float\n        The r2 threshold.\n    temp_dir : Optional[str], optional\n        The temporary directory, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        The clumped snps.\n    \"\"\"\n    chrom = sig_df[ColName.CHR].unique()[0]\n    clump_p_file = f\"{temp_dir}/clump_p_{chrom}.txt\"\n    sig_df[[ColName.SNPID, ColName.P]].to_csv(clump_p_file, sep=\"\\t\", index=False)\n    clump_outfile = f\"{temp_dir}/clump_{chrom}.clumped\"\n    cmd = [\n        self.plink,\n        \"--bfile\",\n        ldref.format(chrom=chrom),\n        \"--clump\",\n        clump_p_file,\n        \"--clump-p1\",\n        str(clump_p1),\n        \"--clump-kb\",\n        str(clump_kb),\n        \"--clump-r2\",\n        str(clump_r2),\n        \"--clump-snp-field\",\n        ColName.SNPID,\n        \"--clump-field\",\n        ColName.P,\n        \"--out\",\n        f\"{temp_dir}/clump_{chrom}\",\n    ]\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        raise RuntimeError(res.stderr)\n    else:\n        if os.path.exists(clump_outfile):\n            clump_snps = pd.read_csv(clump_outfile, delim_whitespace=True, usecols=[\"SNP\"])\n            clump_snps = clump_snps[\"SNP\"].to_list()\n            clump_snps = sig_df[sig_df[ColName.SNPID].isin(clump_snps)]\n            return clump_snps\n        else:\n            logging.warning(f\"No clumped snps found for chromosome {chrom}\")\n            return pd.DataFrame()\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.cojo_slct","title":"<code>cojo_slct(sumstats, ldref, sample_size, cojo_window_kb=10000, cojo_collinear=0.9, diff_freq=0.2, sig_threshold=5e-08, use_ref_EAF=False, temp_dir=None)</code>","text":"<p>Conditional analysis for input sumstatistics.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>The input sumstatistics, from same chromosome or locus.</p> required <code>ldref</code> <code>str</code> <p>The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.</p> required <code>sample_size</code> <code>int</code> <p>The sample size of the input sumstatistics.</p> required <code>cojo_window_kb</code> <code>int</code> <p>The cojo window, by default 10000, unit: kb</p> <code>10000</code> <code>cojo_collinear</code> <code>float</code> <p>The cojo collinear, by default 0.9</p> <code>0.9</code> <code>diff_freq</code> <code>float</code> <p>The difference frequency, by default 0.2</p> <code>0.2</code> <code>sig_threshold</code> <code>float</code> <p>The significance threshold, by default 5e-8</p> <code>5e-08</code> <code>use_ref_EAF</code> <code>bool</code> <p>Whether to use the reference EAF, by default False</p> <code>False</code> <code>temp_dir</code> <code>Optional[str]</code> <p>The temporary directory, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The conditional snps.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>@io_in_tempdir(dir=\"./tmp/loci\")\ndef cojo_slct(\n    self,\n    sumstats: pd.DataFrame,\n    ldref: str,\n    sample_size: int,\n    cojo_window_kb: int = 10000,\n    cojo_collinear: float = 0.9,\n    diff_freq: float = 0.2,\n    sig_threshold: float = 5e-8,\n    use_ref_EAF: bool = False,\n    temp_dir: Optional[str] = None,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Conditional analysis for input sumstatistics.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        The input sumstatistics, from same chromosome or locus.\n    ldref : str\n        The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.\n    sample_size : int\n        The sample size of the input sumstatistics.\n    cojo_window_kb : int, optional\n        The cojo window, by default 10000, unit: kb\n    cojo_collinear : float, optional\n        The cojo collinear, by default 0.9\n    diff_freq : float, optional\n        The difference frequency, by default 0.2\n    sig_threshold : float, optional\n        The significance threshold, by default 5e-8\n    use_ref_EAF : bool, optional\n        Whether to use the reference EAF, by default False\n    temp_dir : Optional[str], optional\n        The temporary directory, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        The conditional snps.\n    \"\"\"\n    chrom = sumstats[ColName.CHR].unique()[0]\n    if not use_ref_EAF and sumstats[ColName.EAF].isnull().any():\n        raise ValueError(f\"{ColName.EAF} is not in the sumstats, please set use_ref_EAF to True\")\n    cojo_input = sumstats.copy()\n    ld = LDRef()\n    cojo_input = ld.intersect(sumstats, ldref, f\"{temp_dir}/cojo_input_{chrom}\", use_ref_EAF)\n    if cojo_input.empty:\n        self.logger.warning(f\"No SNPs in LD reference for chromosome {temp_dir}/cojo_input_{chrom}\")\n        self.logger.warning(\"Use the most significant SNP as the independent lead SNP.\")\n        cojo_snps = sumstats.loc[sumstats.index == sumstats[ColName.P].idxmin()].copy()\n    else:\n        cojo_input[ColName.N] = sample_size\n        cojo_input = cojo_input[\n            [ColName.SNPID, ColName.EA, ColName.NEA, ColName.EAF, ColName.BETA, ColName.SE, ColName.P, ColName.N]\n        ]\n        cojo_input.rename(\n            columns={\n                ColName.SNPID: \"SNP\",\n                ColName.EA: \"A1\",\n                ColName.NEA: \"A2\",\n                ColName.EAF: \"freq\",\n                ColName.BETA: \"b\",\n                ColName.SE: \"se\",\n                ColName.P: \"p\",\n                ColName.N: \"N\",\n            },\n            inplace=True,\n        )\n        cojo_p_file = f\"{temp_dir}/cojo_input_{chrom}.ma\"\n        cojo_input.to_csv(cojo_p_file, sep=\" \", index=False)\n        cojo_outfile = f\"{temp_dir}/cojo_{chrom}.slct\"\n        cmd = [\n            self.gcta,\n            \"--bfile\",\n            f\"{temp_dir}/cojo_input_{chrom}\",\n            \"--cojo-file\",\n            cojo_p_file,\n            \"--cojo-slct\",\n            \"--cojo-p\",\n            str(sig_threshold),\n            \"--cojo-wind\",\n            str(cojo_window_kb),\n            \"--cojo-collinear\",\n            str(cojo_collinear),\n            \"--diff-freq\",\n            str(diff_freq),\n            \"--out\",\n            cojo_outfile,\n        ]\n        self.logger.debug(f\"Run cojo-slct: {' '.join(cmd)}\")\n        res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n        if res.returncode != 0:\n            self.logger.warning(res.stderr)\n            self.logger.warning(f\"Run cojo-slct failed for chromosome {chrom}\")\n            self.logger.warning(\"Use the most significant SNP as the independent lead SNP.\")\n            cojo_snps = sumstats.loc[sumstats[ColName.P] == sumstats[ColName.P].min()].copy()\n        else:\n            if os.path.exists(f\"{cojo_outfile}.jma.cojo\"):\n                cojo_snps = pd.read_csv(\n                    f\"{cojo_outfile}.jma.cojo\", delim_whitespace=True, usecols=[\"SNP\", \"bJ\", \"bJ_se\", \"pJ\"]\n                )\n                cojo_snps.rename(\n                    columns={\n                        \"SNP\": ColName.SNPID,\n                        \"bJ\": ColName.COJO_BETA,\n                        \"bJ_se\": ColName.COJO_SE,\n                        \"pJ\": ColName.COJO_P,\n                    },\n                    inplace=True,\n                )\n                cojo_snps = cojo_snps[cojo_snps[ColName.COJO_P] &lt;= sig_threshold]\n                cojo_snps = sumstats.merge(cojo_snps, on=ColName.SNPID, how=\"inner\")\n            else:\n                self.logger.warning(f\"No conditional snps found for chromosome {chrom}\")\n                self.logger.warning(\"Use the most significant SNP as the independent lead SNP.\")\n                cojo_snps = sumstats.loc[sumstats[ColName.P] == sumstats[ColName.P].min()].copy()\n    return cojo_snps\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.identify_indep_loci","title":"<code>identify_indep_loci(sumstats, sig_threshold=5e-08, loci_extend=500, ldblock=None, if_merge=False, outprefix=None, ldref=None, method='distance', distance=500, clump_kb=500, clump_r2=0.1, sample_size=None, cojo_window_kb=10000, cojo_collinear=0.9, diff_freq=0.2, only_use_sig_snps=False, use_ref_EAF=False, threads=1)</code>","text":"<p>Identify the independent loci.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>The input summary statistics.</p> required <code>sig_threshold</code> <code>float</code> <p>The pvalue threshold, by default 5e-8</p> <code>5e-08</code> <code>loci_extend</code> <code>int</code> <p>The range to extend the independent lead snps to independent loci, by default 500, unit: kb</p> <code>500</code> <code>if_merge</code> <code>bool</code> <p>Whether to merge the overlapped independent loci, by default False</p> <code>False</code> <code>ldref</code> <code>Optional[str]</code> <p>The LD reference file, by default None</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to identify the independent loci, by default \"distance\", choose from [\"distance\", \"clumping\", \"conditional\"]</p> <code>'distance'</code> <code>distance</code> <code>int</code> <p>The distance threshold to identify the independent loci, by default 500, unit: kb</p> <code>500</code> <code>clump_kb</code> <code>int</code> <p>The distance threshold for LD clumping, by default 10000, unit: kb</p> <code>500</code> <code>clump_r2</code> <code>float</code> <p>The r2 threshold for LD clumping, by default 0.1</p> <code>0.1</code> <code>sample_size</code> <code>Optional[int]</code> <p>The sample size for conditional analysis, by default None</p> <code>None</code> <code>cojo_window_kb</code> <code>int</code> <p>The distance threshold for conditional analysis, by default 10000</p> <code>10000</code> <code>cojo_collinear</code> <code>float</code> <p>The collinear threshold for conditional analysis, by default 0.9</p> <code>0.9</code> <code>diff_freq</code> <code>float</code> <p>The difference frequency threshold for conditional analysis, by default 0.2</p> <code>0.2</code> <code>only_use_sig_snps</code> <code>bool</code> <p>Whether to use the significant snps for conditional analysis, by default False</p> <code>False</code> <code>use_ref_EAF</code> <code>bool</code> <p>Whether to use the reference EAF for conditional analysis, by default False</p> <code>False</code> <code>threads</code> <code>int</code> <p>The number of threads, by default 1</p> <code>1</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, DataFrame]</code> <p>The independent lead snps and independent loci.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>def identify_indep_loci(\n    self,\n    sumstats: pd.DataFrame,\n    sig_threshold: float = 5e-8,\n    loci_extend: int = 500,\n    ldblock: Optional[str] = None,\n    if_merge: bool = False,\n    outprefix: Optional[str] = None,\n    ldref: Optional[str] = None,\n    method: str = \"distance\",\n    distance: int = 500,\n    clump_kb: int = 500,\n    clump_r2: float = 0.1,\n    sample_size: Optional[int] = None,\n    cojo_window_kb: int = 10000,\n    cojo_collinear: float = 0.9,\n    diff_freq: float = 0.2,\n    only_use_sig_snps: bool = False,\n    use_ref_EAF: bool = False,\n    threads: int = 1,\n) -&gt; Union[Tuple[pd.DataFrame, pd.DataFrame], None]:\n\"\"\"\n    Identify the independent loci.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        The input summary statistics.\n    sig_threshold : float, optional\n        The pvalue threshold, by default 5e-8\n    loci_extend : int, optional\n        The range to extend the independent lead snps to independent loci, by default 500, unit: kb\n    if_merge : bool, optional\n        Whether to merge the overlapped independent loci, by default False\n    ldref : Optional[str], optional\n        The LD reference file, by default None\n    method : str, optional\n        The method to identify the independent loci, by default \"distance\",\n        choose from [\"distance\", \"clumping\", \"conditional\"]\n    distance : int, optional\n        The distance threshold to identify the independent loci, by default 500, unit: kb\n    clump_kb : int, optional\n        The distance threshold for LD clumping, by default 10000, unit: kb\n    clump_r2 : float, optional\n        The r2 threshold for LD clumping, by default 0.1\n    sample_size : Optional[int], optional\n        The sample size for conditional analysis, by default None\n    cojo_window_kb : int, optional\n        The distance threshold for conditional analysis, by default 10000\n    cojo_collinear : float, optional\n        The collinear threshold for conditional analysis, by default 0.9\n    diff_freq : float, optional\n        The difference frequency threshold for conditional analysis, by default 0.2\n    only_use_sig_snps : bool, optional\n        Whether to use the significant snps for conditional analysis, by default False\n    use_ref_EAF : bool, optional\n        Whether to use the reference EAF for conditional analysis, by default False\n    threads : int, optional\n        The number of threads, by default 1\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, pd.DataFrame]\n        The independent lead snps and independent loci.\n    \"\"\"\n    sumstats = make_SNPID_unique(sumstats)\n    if ldblock is not None:\n        ldblock = pd.read_csv(ldblock, sep=\"\\t\", names=[ColName.CHR, ColName.START, ColName.END])\n    if method == \"distance\":\n        sig_df = get_significant_snps(sumstats, sig_threshold)\n        lead_snp = self.indep_snps_by_distance(sig_df, distance, ldblock)\n    elif method == \"clumping\":\n        clump_p1 = sig_threshold\n        if ldref is not None:\n            sig_df = get_significant_snps(sumstats, sig_threshold)\n            lead_snp = self.indep_snps_by_ldclumping(sig_df, ldref, clump_p1, clump_kb, clump_r2)\n        else:\n            raise ValueError(f\"Please provide the ldref file for method: {method}\")\n    elif method == \"conditional\":\n        if ldref is None:\n            raise ValueError(\"Please provide the ldref file for conditional analysis.\")\n        if sample_size is None:\n            raise ValueError(\"Please provide the sample size for conditional analysis.\")\n        else:\n            lead_snp = self.indep_snps_by_conditional(\n                sumstats,\n                ldref,\n                sample_size,\n                sig_threshold,\n                cojo_window_kb,\n                cojo_collinear,\n                diff_freq,\n                use_ref_EAF,\n                only_use_sig_snps,\n                ldblock,\n                threads,\n            )\n    else:\n        raise ValueError(f\"Unsupported method: {method}\")\n    loci = self.leadsnp2loci(lead_snp, loci_extend, if_merge, ldblock)\n    if if_merge and ColName.COJO_BETA in lead_snp.columns:\n        self.logger.warning(\"The loci identified by cojo may not need merge.\")\n        lead_snp = lead_snp[lead_snp[ColName.SNPID].isin(loci[ColName.LEAD_SNP])]\n    if outprefix:\n        loci_file = f\"{outprefix}.loci.txt\"\n        loci.to_csv(loci_file, sep=\"\\t\", index=False, float_format=\"%.6g\")\n        self.logger.info(f\"Save {len(loci)} independent loci to {loci_file}\")\n        leadsnp_file = f\"{outprefix}.leadsnp.txt\"\n        lead_snp.to_csv(leadsnp_file, sep=\"\\t\", index=False, float_format=\"%.6g\")\n        self.logger.info(f\"Save {len(lead_snp)} independent lead snps to {leadsnp_file}\")\n    return lead_snp, loci\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.indep_snps_by_conditional","title":"<code>indep_snps_by_conditional(sumstats, ldref, sample_size, sig_threshold=5e-08, cojo_window_kb=10000, cojo_collinear=0.9, diff_freq=0.2, use_ref_EAF=False, only_use_sig_snps=False, ldblock=None, threads=1)</code>  <code>staticmethod</code>","text":"<p>Identify the independent snps by conditional analysis.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>The summary statistics.</p> required <code>ldref</code> <code>str</code> <p>The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.</p> required <code>sample_size</code> <code>int</code> <p>The sample size.</p> required <code>sig_threshold</code> <code>float</code> <p>The significance threshold, by default 5e-8</p> <code>5e-08</code> <code>cojo_window_kb</code> <code>int</code> <p>The cojo window, by default 10000, in kb</p> <code>10000</code> <code>cojo_collinear</code> <code>float</code> <p>The cojo collinear, by default 0.9</p> <code>0.9</code> <code>diff_freq</code> <code>float</code> <p>The difference frequency, by default 0.2</p> <code>0.2</code> <code>use_ref_EAF</code> <code>bool</code> <p>Whether to use the reference EAF, by default False</p> <code>False</code> <code>only_use_sig_snps</code> <code>bool</code> <p>Whether to only use the significant snps, by default False</p> <code>False</code> <code>ldblock</code> <code>Optional[DataFrame]</code> <p>The LD block, run cojo in each LD block, by default None</p> <code>None</code> <code>threads</code> <code>int</code> <p>The number of threads, by default 1</p> <code>1</code> Source code in <code>easyfinemap/loci.py</code> <pre><code>@staticmethod\ndef indep_snps_by_conditional(\n    sumstats: pd.DataFrame,\n    ldref: str,\n    sample_size: int,\n    sig_threshold: float = 5e-8,\n    cojo_window_kb: int = 10000,\n    cojo_collinear: float = 0.9,\n    diff_freq: float = 0.2,\n    use_ref_EAF: bool = False,\n    only_use_sig_snps: bool = False,\n    ldblock: Optional[pd.DataFrame] = None,\n    threads: int = 1,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Identify the independent snps by conditional analysis.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        The summary statistics.\n    ldref : str\n        The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.\n    sample_size : int\n        The sample size.\n    sig_threshold : float, optional\n        The significance threshold, by default 5e-8\n    cojo_window_kb : int, optional\n        The cojo window, by default 10000, in kb\n    cojo_collinear : float, optional\n        The cojo collinear, by default 0.9\n    diff_freq : float, optional\n        The difference frequency, by default 0.2\n    use_ref_EAF : bool, optional\n        Whether to use the reference EAF, by default False\n    only_use_sig_snps : bool, optional\n        Whether to only use the significant snps, by default False\n    ldblock : Optional[pd.DataFrame], optional\n        The LD block, run cojo in each LD block, by default None\n    threads : int, optional\n        The number of threads, by default 1\n    \"\"\"\n    logger = logging.getLogger('COJO')\n    if not use_ref_EAF and ColName.EAF not in sumstats.columns:\n        raise ValueError(f\"{ColName.EAF} is not in the sumstats, please set use_ref_EAF to True\")\n    sig_df = sumstats[sumstats[ColName.P] &lt;= sig_threshold]\n    logger.debug(f\"Number of significant snps: {len(sig_df)}\")\n    logger.debug(f\"Number of chromosomes: {len(sig_df[ColName.CHR].unique())}\")\n    args_list = []\n    loci = Loci()\n    if ldblock is not None:\n        sig_blocks = loci.indep_snps_by_distance(sig_df, ldblock=ldblock)\n        sig_blocks = loci.leadsnp2loci(sig_blocks, ldblock=ldblock)\n        for i in sig_blocks.index:\n            if only_use_sig_snps:\n                in_df = sig_df[\n                    (sig_df[ColName.CHR] == sig_blocks.loc[i][ColName.CHR])\n                    &amp; (sig_df[ColName.BP] &gt;= sig_blocks.loc[i][ColName.START])\n                    &amp; (sig_df[ColName.BP] &lt;= sig_blocks.loc[i][ColName.END])\n                ]\n            else:\n                in_df = sumstats[\n                    (sumstats[ColName.CHR] == sig_blocks.loc[i][ColName.CHR])\n                    &amp; (sumstats[ColName.BP] &gt;= sig_blocks.loc[i][ColName.START])\n                    &amp; (sumstats[ColName.BP] &lt;= sig_blocks.loc[i][ColName.END])\n                ]\n            args_list.append(\n                (\n                    in_df,\n                    ldref.format(chrom=sig_blocks.loc[i][ColName.CHR]),\n                    sample_size,\n                    cojo_window_kb,\n                    cojo_collinear,\n                    diff_freq,\n                    sig_threshold,\n                    use_ref_EAF,\n                )\n            )\n    else:\n        for chrom in sig_df[ColName.CHR].unique():\n            if only_use_sig_snps:\n                in_df = sig_df[sig_df[ColName.CHR] == chrom]\n            else:\n                in_df = sumstats[sumstats[ColName.CHR] == chrom]\n            # in_df = in_df[in_df[ColName.P] &lt;= 0.05]\n            args_list.append(\n                (\n                    in_df,\n                    ldref.format(chrom=chrom),\n                    sample_size,\n                    cojo_window_kb,\n                    cojo_collinear,\n                    diff_freq,\n                    sig_threshold,\n                    use_ref_EAF,\n                )\n            )\n\n    with ProcessPoolExecutor(max_workers=threads) as executor:\n        results = []\n        with Progress(\n            TextColumn(\"{task.description}\"),\n            BarColumn(),\n            MofNCompleteColumn(),\n            TimeElapsedColumn(),\n            auto_refresh=True,\n        ) as progress:\n            task = progress.add_task(\"Run cojo-slct\", total=len(args_list))\n            for _ in executor.map(loci.cojo_slct, *zip(*args_list)):\n                progress.update(task, advance=1)\n                progress.refresh()\n                results.append(_)\n    cojo_snps = pd.concat(results, axis=0, ignore_index=True)\n    return cojo_snps\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.indep_snps_by_distance","title":"<code>indep_snps_by_distance(sig_df, distance=500, ldblock=None)</code>  <code>staticmethod</code>","text":"<p>Identify the independent snps by distance only.</p> <p>Parameters:</p> Name Type Description Default <code>sig_df</code> <code>DataFrame</code> <p>The significant snps.</p> required <code>distance</code> <code>int</code> <p>The distance threshold, by default 500, unit: kb</p> <code>500</code> <code>ldblock</code> <code>Optional[DataFrame]</code> <p>The ld block information, use boundary to identify the independent snps, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The independent snps.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>@staticmethod\ndef indep_snps_by_distance(\n    sig_df: pd.DataFrame, distance: int = 500, ldblock: Optional[pd.DataFrame] = None\n) -&gt; pd.DataFrame:\n\"\"\"\n    Identify the independent snps by distance only.\n\n    Parameters\n    ----------\n    sig_df : pd.DataFrame\n        The significant snps.\n    distance : int, optional\n        The distance threshold, by default 500, unit: kb\n    ldblock : Optional[pd.DataFrame], optional\n        The ld block information, use boundary to identify the independent snps, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        The independent snps.\n    \"\"\"\n    sig_df = sig_df.sort_values(ColName.P).copy()\n    lead_snp = []\n    if ldblock is not None:\n        while len(sig_df):\n            lead_snp.append(sig_df.iloc[[0]])\n            sig_block = ldblock[\n                (ldblock[ColName.CHR] == sig_df.iloc[0][ColName.CHR])\n                &amp; (ldblock[ColName.START] &lt;= sig_df.iloc[0][ColName.BP])\n                &amp; (ldblock[ColName.END] &gt;= sig_df.iloc[0][ColName.BP])\n            ]\n            sig_df = sig_df[\n                ~(\n                    (sig_df[ColName.CHR] == sig_df.iloc[0][ColName.CHR])\n                    &amp; (sig_df[ColName.BP] &gt;= sig_block.iloc[0][ColName.START])\n                    &amp; (sig_df[ColName.BP] &lt;= sig_block.iloc[0][ColName.END])\n                )\n            ]\n    else:\n        distance = distance * 1000\n        while len(sig_df):\n            lead_snp.append(sig_df.iloc[[0]])\n            sig_df = sig_df[\n                ~(\n                    (sig_df[ColName.CHR] == sig_df.iloc[0][ColName.CHR])\n                    &amp; (sig_df[ColName.BP] &gt;= sig_df.iloc[0][ColName.BP] - distance)\n                    &amp; (sig_df[ColName.BP] &lt;= sig_df.iloc[0][ColName.BP] + distance)\n                )\n            ]  # type: ignore\n    lead_snp = pd.concat(lead_snp, axis=0, ignore_index=True)\n    return lead_snp\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.indep_snps_by_ldclumping","title":"<code>indep_snps_by_ldclumping(sig_df, ldref, clump_p1=5e-08, clump_kb=500, clump_r2=0.1)</code>  <code>staticmethod</code>","text":"<p>Identify the independent snps by LD clumping.</p> <p>Parameters:</p> Name Type Description Default <code>sig_df</code> <code>DataFrame</code> <p>The significant snps.</p> required <code>ldref</code> <code>str</code> <p>The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.</p> required <code>clump_p1</code> <code>float</code> <p>The p1 threshold, by default 5e-8</p> <code>5e-08</code> <code>clump_kb</code> <code>int</code> <p>The kb threshold, by default 500, unit: kb</p> <code>500</code> <code>clump_r2</code> <code>float</code> <p>The r2 threshold, by default 0.1</p> <code>0.1</code> <p>Returns:</p> Type Description <code>DataFrame</code> Source code in <code>easyfinemap/loci.py</code> <pre><code>@staticmethod\ndef indep_snps_by_ldclumping(\n    sig_df: pd.DataFrame, ldref: str, clump_p1: float = 5e-8, clump_kb: int = 500, clump_r2: float = 0.1\n) -&gt; pd.DataFrame:\n\"\"\"\n    Identify the independent snps by LD clumping.\n\n    Parameters\n    ----------\n    sig_df : pd.DataFrame\n        The significant snps.\n    ldref : str\n        The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.\n    clump_p1 : float, optional\n        The p1 threshold, by default 5e-8\n    clump_kb : int, optional\n        The kb threshold, by default 500, unit: kb\n    clump_r2 : float, optional\n        The r2 threshold, by default 0.1\n\n    Returns\n    -------\n    pd.DataFrame\n    \"\"\"\n    clumped_snps = []\n    for chrom in sig_df[ColName.CHR].unique():\n        sig_df_chr = sig_df[sig_df[ColName.CHR] == chrom]\n        clumped_snps.append(Loci().clump_per_chr(sig_df_chr, ldref, clump_p1, clump_kb, clump_r2))  # type: ignore\n    clumped_snps = pd.concat(clumped_snps, axis=0, ignore_index=True)\n    return clumped_snps\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.leadsnp2loci","title":"<code>leadsnp2loci(lead_snps, range=500, if_merge=False, ldblock=None)</code>  <code>staticmethod</code>","text":"<p>Expand the independent lead snps to independent loci by given range.</p> <p>Parameters:</p> Name Type Description Default <code>lead_snps</code> <code>DataFrame</code> <p>The independent lead snps.</p> required <code>range</code> <code>int</code> <p>The range, by default 500, unit: kb</p> <code>500</code> <code>if_merge</code> <code>bool</code> <p>Whether merge the overlapped loci, by default False</p> <code>False</code> <code>ldblock</code> <code>Optional[DataFrame]</code> <p>The ld block, using LD block to expand the independent loci, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The independent loci.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>@staticmethod\ndef leadsnp2loci(\n    lead_snps: pd.DataFrame, range: int = 500, if_merge: bool = False, ldblock: Optional[pd.DataFrame] = None\n) -&gt; pd.DataFrame:\n\"\"\"\n    Expand the independent lead snps to independent loci by given range.\n\n    Parameters\n    ----------\n    lead_snps : pd.DataFrame\n        The independent lead snps.\n    range : int, optional\n        The range, by default 500, unit: kb\n    if_merge : bool, optional\n        Whether merge the overlapped loci, by default False\n    ldblock : Optional[pd.DataFrame], optional\n        The ld block, using LD block to expand the independent loci, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        The independent loci.\n    \"\"\"\n    loci_df = lead_snps.copy()\n    loci_df = loci_df[[ColName.CHR, ColName.BP, ColName.P, ColName.SNPID]]\n    loci_df.columns = [ColName.CHR, ColName.LEAD_SNP_BP, ColName.LEAD_SNP_P, ColName.LEAD_SNP]  # type: ignore\n    if ldblock is not None:\n        loci_df[ColName.START] = 0\n        loci_df[ColName.END] = 0\n        for i in loci_df.index:\n            sub_ldblock = ldblock[\n                (ldblock[ColName.CHR] == loci_df.loc[i, ColName.CHR])\n                &amp; (ldblock[ColName.START] &lt;= loci_df.loc[i, ColName.LEAD_SNP_BP])\n                &amp; (ldblock[ColName.END] &gt;= loci_df.loc[i, ColName.LEAD_SNP_BP])\n            ]\n            if sub_ldblock.empty:\n                continue\n            else:\n                loci_df.loc[i, ColName.START] = sub_ldblock.iloc[0][ColName.START]\n                loci_df.loc[i, ColName.END] = sub_ldblock.iloc[0][ColName.END]\n    else:\n        range = range * 1000\n\n        loci_df[ColName.START] = loci_df[ColName.LEAD_SNP_BP] - range\n        loci_df[ColName.START] = loci_df[ColName.START].apply(lambda x: 1 if x &lt;= 0 else x)\n        loci_df[ColName.END] = loci_df[ColName.LEAD_SNP_BP] + range\n    loci_df = loci_df[ColName.loci_cols].copy()\n    if if_merge:\n        loci_df = Loci.merge_overlapped_loci(loci_df)\n    loci_df = loci_df.sort_values(by=[ColName.CHR, ColName.START, ColName.END])\n    return loci_df\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.merge_overlapped_loci","title":"<code>merge_overlapped_loci(loci_df)</code>  <code>staticmethod</code>","text":"<p>Merge the overlapped loci.</p> <p>Parameters:</p> Name Type Description Default <code>loci_df</code> <code>DataFrame</code> <p>The independent loci.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The merged independent loci.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>@staticmethod\ndef merge_overlapped_loci(loci_df: pd.DataFrame):\n\"\"\"\n    Merge the overlapped loci.\n\n    Parameters\n    ----------\n    loci_df : pd.DataFrame\n        The independent loci.\n\n    Returns\n    -------\n    pd.DataFrame\n        The merged independent loci.\n    \"\"\"\n    merged_loci = loci_df.copy()\n    merged_loci.sort_values([ColName.CHR, ColName.START, ColName.END], inplace=True)\n    merged_loci['no_overlap'] = merged_loci[ColName.START] &gt; merged_loci[ColName.END].shift().cummax()\n    merged_loci['diff_chr'] = merged_loci[ColName.CHR] != merged_loci[ColName.CHR].shift()\n    merged_loci[\"break\"] = merged_loci[\"no_overlap\"] | merged_loci['diff_chr']\n    merged_loci['group'] = merged_loci['break'].cumsum()\n    merged_loci = merged_loci.sort_values(['group', ColName.LEAD_SNP_P], ascending=True)\n    agg_func = {}\n    for col in loci_df.columns:\n        if col == ColName.START:\n            agg_func[col] = 'min'\n        elif col == ColName.END:\n            agg_func[col] = 'max'\n        else:\n            agg_func[col] = 'first'\n    result = merged_loci.groupby(\"group\").agg(agg_func)\n    result.reset_index(drop=True, inplace=True)\n    return result\n</code></pre>"},{"location":"api/cli/","title":"Cli","text":"<p>Console script for easy_finemap.</p>"},{"location":"api/cli/#easyfinemap.cli.FinemapMethod","title":"<code>FinemapMethod</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>The method to perform fine-mapping.</p>"},{"location":"api/cli/#easyfinemap.cli.LociMethod","title":"<code>LociMethod</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>The method to identify the lead SNPs.</p>"},{"location":"api/cli/#easyfinemap.cli.fine_mapping","title":"<code>fine_mapping(sumstats_path=typer.Argument(..., help='The path to the GWAS summary statistics file.'), loci_path=typer.Argument(..., help='The path to the loci file, generated by get-loci command.'), lead_snps_path=typer.Argument(..., help='The path to the lead SNPs file, generated by get-loci command.'), methods=typer.Option(..., '--methods', '-m', help='The methods to use.'), outfile=typer.Argument(..., help='The output file.'), var_prior=typer.Option(0.2, '--var-prior', help='The prior variance for the aBF method.'), conditional=typer.Option(False, '--conditional', '-c', help='Whether to use conditional mode.'), prior_file=typer.Option(None, '--prior-file', help='The path to the prior file.'), sample_size=typer.Option(None, '--sample-size', '-n', help='The sample size for conditional mode.'), ldref=typer.Option(None, '--ldref', help='The path to the LD reference file.'), cond_snps_wind_kb=typer.Option(10000, '--cond-snps-wind-kb', help='The conditional SNPs window size, in kb.'), max_causal=typer.Option(1, '--max-causal', help='The maximum number of causal SNPs.'), credible_threshold=typer.Option(None, '--credible-threshold', help='The credible threshold.'), credible_method=typer.Option(None, '--credible-method', help='The fine-mapping method for credible set.'), use_ref_EAF=typer.Option(False, '--use-ref-eaf', help='Whether to use the reference panel EAF.'), threads=typer.Option(1, '--threads', '-t', help='The number of threads.'))</code>","text":"<p>Fine mapping.</p> Source code in <code>easyfinemap/cli.py</code> <pre><code>@app.command()\ndef fine_mapping(\n    sumstats_path: str = typer.Argument(..., help=\"The path to the GWAS summary statistics file.\"),\n    loci_path: str = typer.Argument(..., help=\"The path to the loci file, generated by get-loci command.\"),\n    lead_snps_path: str = typer.Argument(..., help=\"The path to the lead SNPs file, generated by get-loci command.\"),\n    methods: List[FinemapMethod] = typer.Option(..., \"--methods\", \"-m\", help=\"The methods to use.\"),\n    outfile: str = typer.Argument(..., help=\"The output file.\"),\n    var_prior: float = typer.Option(0.2, \"--var-prior\", help=\"The prior variance for the aBF method.\"),\n    conditional: bool = typer.Option(False, \"--conditional\", \"-c\", help=\"Whether to use conditional mode.\"),\n    prior_file: Optional[str] = typer.Option(None, \"--prior-file\", help=\"The path to the prior file.\"),\n    sample_size: Optional[int] = typer.Option(\n        None, \"--sample-size\", \"-n\", help=\"The sample size for conditional mode.\"\n    ),\n    ldref: str = typer.Option(None, \"--ldref\", help=\"The path to the LD reference file.\"),\n    cond_snps_wind_kb: int = typer.Option(\n        10000, \"--cond-snps-wind-kb\", help=\"The conditional SNPs window size, in kb.\"\n    ),\n    max_causal: int = typer.Option(1, \"--max-causal\", help=\"The maximum number of causal SNPs.\"),\n    credible_threshold: Optional[float] = typer.Option(None, \"--credible-threshold\", help=\"The credible threshold.\"),\n    credible_method: Optional[str] = typer.Option(\n        None, \"--credible-method\", help=\"The fine-mapping method for credible set.\"\n    ),\n    use_ref_EAF: bool = typer.Option(False, \"--use-ref-eaf\", help=\"Whether to use the reference panel EAF.\"),\n    threads: int = typer.Option(1, \"--threads\", \"-t\", help=\"The number of threads.\"),\n) -&gt; None:\n\"\"\"Fine mapping.\"\"\"\n    if os.path.exists(sumstats_path) and os.path.exists(loci_path) and os.path.exists(lead_snps_path):\n        # sumstats = pd.read_csv(sumstats_path, sep=\"\\t\")\n        loci = pd.read_csv(loci_path, sep=\"\\t\")\n        lead_snps = pd.read_csv(lead_snps_path, sep=\"\\t\")\n        EasyFinemap().finemap_all_loci(\n            sumstats=sumstats_path,\n            loci=loci,\n            lead_snps=lead_snps,\n            methods=methods,  # type: ignore\n            outfile=outfile,\n            var_prior=var_prior,\n            conditional=conditional,\n            prior_file=prior_file,\n            sample_size=sample_size,\n            ldref=ldref,\n            cond_snps_wind_kb=cond_snps_wind_kb,\n            max_causal=max_causal,\n            credible_threshold=credible_threshold,\n            credible_method=credible_method,\n            use_ref_EAF=use_ref_EAF,\n            threads=threads,\n        )\n    else:\n        logging.error(f\"No such file of {sumstats_path} or {loci_path} or {lead_snps_path}.\")\n        sys.exit(1)\n</code></pre>"},{"location":"api/cli/#easyfinemap.cli.get_loci","title":"<code>get_loci(sumstats_path=typer.Argument(..., help='The path to the GWAS summary statistics file.'), output=typer.Argument(..., help='The output prefix.'), sig_threshold=typer.Option(5e-08, '--sig-threshold', '-s', help='The significance threshold.'), loci_extension=typer.Option(500, '--loci-extension', '-l', help='The extension from lead SNPs, in kb'), ldblock=typer.Option(None, '--ldblock', help='The path to the LD block file.'), if_merge=typer.Option(False, '--merge-loci', '-i', help='Whether to merge the loci, not recommanded for conditional mode.'), method=typer.Option(LociMethod.distance, '--method', '-m', help='The method to identify the lead SNPs.'), distance=typer.Option(50, '--distance', '-d', help='The distance threshold for distance method, in kb.'), ldref=typer.Option(None, '--ldref', help='The path to the LD reference file.'), clump_kb=typer.Option(500, '--clump-kb', '-c', help='The clumping window size, in kb.'), clump_r2=typer.Option(0.1, '--clump-r2', '-r', help='The clumping r2 threshold.'), sample_size=typer.Option(None, '--sample-size', '-n', help='The sample size for conditional method.'), cojo_window_kb=typer.Option(10000, '--cojo-window-kb', help='The cojo window size, in kb.'), cojo_collinear=typer.Option(0.9, '--cojo-collinear', help='The cojo collinear threshold.'), diff_freq=typer.Option(0.2, '--diff-freq', help='The difference in allele frequency threshold.'), use_ref_eaf=typer.Option(False, '--use-ref-eaf', help='Whether to use the reference panel EAF.'), only_use_sig_snps=typer.Option(False, '--only-use-sig-snps', help='Whether to only use the significant SNPs.'), threads=typer.Option(1, '--threads', '-t', help='The number of threads.'))</code>","text":"<p>Get the loci from the GWAS summary statistics file.</p> Source code in <code>easyfinemap/cli.py</code> <pre><code>@app.command()\ndef get_loci(\n    sumstats_path: Path = typer.Argument(..., help=\"The path to the GWAS summary statistics file.\"),\n    output: str = typer.Argument(..., help=\"The output prefix.\"),\n    sig_threshold: float = typer.Option(5e-8, \"--sig-threshold\", \"-s\", help=\"The significance threshold.\"),\n    loci_extension: int = typer.Option(500, \"--loci-extension\", \"-l\", help=\"The extension from lead SNPs, in kb\"),\n    ldblock: str = typer.Option(None, \"--ldblock\", help=\"The path to the LD block file.\"),\n    if_merge: bool = typer.Option(\n        False, \"--merge-loci\", \"-i\", help=\"Whether to merge the loci, not recommanded for conditional mode.\"\n    ),\n    method: LociMethod = typer.Option(\n        LociMethod.distance, \"--method\", \"-m\", help=\"The method to identify the lead SNPs.\"\n    ),\n    distance: int = typer.Option(50, \"--distance\", \"-d\", help=\"The distance threshold for distance method, in kb.\"),\n    ldref: str = typer.Option(None, \"--ldref\", help=\"The path to the LD reference file.\"),\n    clump_kb: int = typer.Option(500, \"--clump-kb\", \"-c\", help=\"The clumping window size, in kb.\"),\n    clump_r2: float = typer.Option(0.1, \"--clump-r2\", \"-r\", help=\"The clumping r2 threshold.\"),\n    sample_size: int = typer.Option(None, \"--sample-size\", \"-n\", help=\"The sample size for conditional method.\"),\n    cojo_window_kb: int = typer.Option(10000, \"--cojo-window-kb\", help=\"The cojo window size, in kb.\"),\n    cojo_collinear: float = typer.Option(0.9, \"--cojo-collinear\", help=\"The cojo collinear threshold.\"),\n    diff_freq: float = typer.Option(0.2, \"--diff-freq\", help=\"The difference in allele frequency threshold.\"),\n    use_ref_eaf: bool = typer.Option(False, \"--use-ref-eaf\", help=\"Whether to use the reference panel EAF.\"),\n    only_use_sig_snps: bool = typer.Option(\n        False, \"--only-use-sig-snps\", help=\"Whether to only use the significant SNPs.\"\n    ),\n    threads: int = typer.Option(1, \"--threads\", \"-t\", help=\"The number of threads.\"),\n) -&gt; None:\n\"\"\"Get the loci from the GWAS summary statistics file.\"\"\"\n    if sumstats_path.exists():\n        logging.info(f\"Loading {sumstats_path}...\")\n        sumstats = pd.read_csv(sumstats_path, sep=\"\\t\")\n        Loci().identify_indep_loci(\n            sumstats=sumstats,\n            sig_threshold=sig_threshold,\n            loci_extend=loci_extension,\n            ldblock=ldblock,\n            if_merge=if_merge,\n            outprefix=output,\n            ldref=ldref,\n            method=method,\n            distance=distance,\n            clump_kb=clump_kb,\n            clump_r2=clump_r2,\n            sample_size=sample_size,\n            cojo_window_kb=cojo_window_kb,\n            cojo_collinear=cojo_collinear,\n            diff_freq=diff_freq,\n            use_ref_EAF=use_ref_eaf,\n            only_use_sig_snps=only_use_sig_snps,\n            threads=threads,\n        )\n    else:\n        logging.error(f\"No such file of {sumstats_path}.\")\n        sys.exit(1)\n</code></pre>"},{"location":"api/cli/#easyfinemap.cli.main","title":"<code>main(version=typer.Option(False, '--version', '-V', help='Show version.'), verbose=typer.Option(False, '--verbose', '-v', help='Show verbose info.'))</code>","text":"Source code in <code>easyfinemap/cli.py</code> <pre><code>@app.callback(invoke_without_command=True, no_args_is_help=True)\ndef main(\n    version: bool = typer.Option(False, '--version', '-V', help='Show version.'),\n    verbose: bool = typer.Option(False, '--verbose', '-v', help='Show verbose info.'),\n):\n\"\"\"EasyFinemap: A user-friendly tool for fine-mapping.\"\"\"\n    console = Console()\n    console.rule(\"[bold blue]EasyFinemap[/bold blue]\")\n    console.print(f\"Version: {__version__}\", justify=\"center\")\n    console.print(\"Author: Jianhua Wang\", justify=\"center\")\n    console.print(\"Email: jianhua.mert@gmail.com\", justify=\"center\")\n    if version:\n        typer.echo(f'EasyFinemap version: {__version__}')\n        raise typer.Exit()\n    if verbose:\n        logging.getLogger().setLevel(logging.DEBUG)\n        logging.info('Verbose mode is on.')\n    else:\n        logging.getLogger().setLevel(logging.INFO)\n</code></pre>"},{"location":"api/cli/#easyfinemap.cli.validate_ldref","title":"<code>validate_ldref(ldref_path=typer.Argument(..., help='The path to the LD reference file.'), outprefix=typer.Argument(..., help='The output prefix.'), file_type=typer.Option('plink', '--file-type', '-f', help='The file type of the LD reference file.'), mac=typer.Option(10, '--mac', '-m', help='The minor allele count threshold.'), threads=typer.Option(1, '--threads', '-t', help='The number of threads.'))</code>","text":"<p>Validate the LD reference file.</p> Source code in <code>easyfinemap/cli.py</code> <pre><code>@app.command()\ndef validate_ldref(\n    ldref_path: str = typer.Argument(..., help=\"The path to the LD reference file.\"),\n    outprefix: str = typer.Argument(..., help=\"The output prefix.\"),\n    file_type: str = typer.Option(\"plink\", \"--file-type\", \"-f\", help=\"The file type of the LD reference file.\"),\n    mac: int = typer.Option(10, \"--mac\", \"-m\", help=\"The minor allele count threshold.\"),\n    threads: int = typer.Option(1, \"--threads\", \"-t\", help=\"The number of threads.\"),\n) -&gt; None:\n\"\"\"Validate the LD reference file.\"\"\"\n    ld = LDRef()\n    ld.valid(ldref_path, outprefix, file_type, mac, threads)\n</code></pre>"},{"location":"api/easyfinemap/","title":"EasyFinemap","text":"<p>             Bases: <code>object</code></p> <p>Main class.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def __init__(self):\n\"\"\"Initialize.\"\"\"\n    self.logger = logging.getLogger('EasyFinemap')\n    tool = Tools()\n    self.finemap = tool.finemap\n    self.paintor = tool.paintor\n    self.gcta = tool.gcta\n    self.plink = tool.plink\n    self.bcftools = tool.bcftools\n    self.caviarbf = tool.caviarbf\n    self.model_search = tool.model_search\n    self.tmp_root = Path.cwd() / \"tmp\" / \"easyfinemap\"\n    if not self.tmp_root.exists():\n        self.tmp_root.mkdir(parents=True)\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.annotate_prior","title":"<code>annotate_prior(sumstats, prior_file)</code>","text":"<p>Annotate prior from polyfun results.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>prior_file</code> <code>str</code> <p>Path to prior file, present only support polyfun's results: https://github.com/omerwe/polyfun/blob/master/snpvar_meta.chr1_7.parquet https://github.com/omerwe/polyfun/blob/master/snpvar_meta.chr1_7.parquet</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Annotated summary statistics.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def annotate_prior(\n    self,\n    sumstats: pd.DataFrame,\n    prior_file: str,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Annotate prior from polyfun results.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    prior_file : str\n        Path to prior file, present only support polyfun's results:\n        https://github.com/omerwe/polyfun/blob/master/snpvar_meta.chr1_7.parquet\n        https://github.com/omerwe/polyfun/blob/master/snpvar_meta.chr1_7.parquet\n\n    Returns\n    -------\n    pd.DataFrame\n        Annotated summary statistics.\n    \"\"\"\n    # check tabix index\n    if not os.path.exists(f\"{prior_file}.tbi\"):\n        raise ValueError(f\"No tabix index for {prior_file}\")\n    # check header\n    header = pd.read_csv(prior_file, sep=\"\\t\", nrows=0).columns.tolist()\n    if 'snpvar_bin' not in header:\n        raise ValueError(f\"No snpvar_bin in {prior_file}\")\n    # annotate\n    tb = tabix.open(prior_file)\n    chrom = sumstats[ColName.CHR].unique()[0]\n    start = sumstats[ColName.BP].min()\n    end = sumstats[ColName.BP].max()\n    prior_df = pd.DataFrame(data=tb.query(str(chrom), start, end), columns=header)\n    prior_df = prior_df.rename(columns={\"snpvar_bin\": \"SNPVAR\"})\n    prior_df['SNPVAR'] = prior_df['SNPVAR'].astype(float)\n    prior_df = sg.make_SNPID_unique(prior_df, ColName.CHR, ColName.BP, 'A1', 'A2')\n    prior_df = prior_df.drop_duplicates(subset=ColName.SNPID)\n    prior_map = prior_df[['SNPID', 'SNPVAR']].set_index('SNPID').to_dict()['SNPVAR']\n    sumstats['SNPVAR'] = sumstats[ColName.SNPID].map(prior_map).fillna(0)\n    return sumstats\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.cond_sumstat","title":"<code>cond_sumstat(sumstats, lead_snp, lead_snps, ldref, sample_size, use_ref_EAF=False, cond_snps_wind_kb=1000, temp_dir=None, **kwargs)</code>","text":"<p>Conditional sumstat.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>lead_snp</code> <code>str</code> <p>Lead SNP.</p> required <code>ldref</code> <code>str</code> <p>Path to LD reference.</p> required <code>sample_size</code> <code>int</code> <p>Sample size.</p> required <code>use_ref_EAF</code> <code>bool</code> <p>Use reference EAF, by default False</p> <code>False</code> <code>cond_snps_wind_kb</code> <code>int</code> <p>Conditional SNPs window in kb, by default 1000</p> <code>1000</code> <code>temp_dir</code> <code>Optional[str]</code> <p>Path to tempdir, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Conditional sumstat.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>@io_in_tempdir('./tmp/easyfinemap')\ndef cond_sumstat(\n    self,\n    sumstats: pd.DataFrame,\n    lead_snp: str,\n    lead_snps: pd.DataFrame,\n    ldref: str,\n    sample_size: int,\n    use_ref_EAF: bool = False,\n    cond_snps_wind_kb: int = 1000,\n    temp_dir: Optional[str] = None,\n    **kwargs,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Conditional sumstat.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    lead_snp : str\n        Lead SNP.\n    ldref : str\n        Path to LD reference.\n    sample_size : int\n        Sample size.\n    use_ref_EAF : bool, optional\n        Use reference EAF, by default False\n    cond_snps_wind_kb : int, optional\n        Conditional SNPs window in kb, by default 1000\n    temp_dir : Optional[str], optional\n        Path to tempdir, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        Conditional sumstat.\n    \"\"\"\n    if lead_snp is None:\n        raise ValueError(\"Lead SNP is required for conditional finemapping\")\n    if lead_snps is None:\n        raise ValueError(\"Lead SNPs are required for conditional finemapping\")\n    lead_snp_chr = lead_snps.loc[lead_snps[ColName.SNPID] == lead_snp, ColName.CHR].values[0]\n    lead_snp_bp: int = lead_snps.loc[lead_snps[ColName.SNPID] == lead_snp, ColName.BP].values[0]  # type: ignore\n    cond_snps = lead_snps[\n        (lead_snps[ColName.CHR] == lead_snp_chr)\n        &amp; (lead_snps[ColName.BP] &gt;= lead_snp_bp - cond_snps_wind_kb * 1000)\n        &amp; (lead_snps[ColName.BP] &lt;= lead_snp_bp + cond_snps_wind_kb * 1000)\n        &amp; (lead_snps[ColName.SNPID] != lead_snp)\n    ].copy()\n    if cond_snps.empty:\n        self.logger.debug(f\"No conditional SNPs found for {lead_snp}\")\n        cond_res = sumstats.copy()\n        cond_res[ColName.COJO_BETA] = cond_res[ColName.BETA]\n        cond_res[ColName.COJO_SE] = cond_res[ColName.SE]\n        cond_res[ColName.COJO_P] = cond_res[ColName.P]\n    else:\n        ld = LDRef()\n        for col in [ColName.COJO_P, ColName.COJO_BETA, ColName.COJO_SE]:\n            if col in cond_snps.columns:\n                cond_snps.drop(columns=[col], inplace=True)\n        chrom = lead_snp_chr\n        all_sumstats = pd.concat([sumstats, cond_snps], ignore_index=True)\n        all_sumstats.drop_duplicates(subset=[ColName.SNPID], inplace=True)\n        all_sumstats.sort_values(by=[ColName.CHR, ColName.BP], inplace=True)\n        all_sumstats.reset_index(drop=True, inplace=True)\n        cojo_input = ld.intersect(\n            all_sumstats, ldref, f\"{temp_dir}/cojo_input_{chrom}\", use_ref_EAF\n        )\n        self.logger.debug(f\"Lead SNP: {lead_snp}\")\n        self.logger.debug(f\"Conditional SNPs: {cond_snps['SNPID'].tolist()}\")\n        cond_res = ld.cojo_cond(\n            cojo_input, cond_snps, f\"{temp_dir}/cojo_input_{chrom}\", sample_size, use_ref_EAF\n        )  # type: ignore\n    return cond_res\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.finemap_all_loci","title":"<code>finemap_all_loci(sumstats, loci, lead_snps, methods, var_prior=0.2, conditional=False, prior_file=None, sample_size=None, ldref=None, cond_snps_wind_kb=1000, max_causal=1, credible_threshold=None, credible_method=None, use_ref_EAF=False, outfile=None, threads=1)</code>","text":"<p>Perform finemapping for all loci.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>loci</code> <code>DataFrame</code> <p>Loci.</p> required <code>lead_snps</code> <code>DataFrame</code> <p>Lead SNPs.</p> required <code>methods</code> <code>List[str]</code> <p>Finemapping methods.</p> required <code>var_prior</code> <code>float</code> <p>Variance prior, by default 0.2</p> <code>0.2</code> <code>conditional</code> <code>bool</code> <p>Conditional finemapping, by default False</p> <code>False</code> <code>prior_file</code> <code>Optional[str]</code> <p>Path to prior file, by default None</p> <code>None</code> <code>sample_size</code> <code>Optional[int]</code> <p>Sample size, by default None</p> <code>None</code> <code>ldref</code> <code>Optional[str]</code> <p>LD reference, by default None</p> <code>None</code> <code>cond_snps_wind_kb</code> <code>int</code> <p>Conditional SNPs window, by default 1000</p> <code>1000</code> <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants, by default 1</p> <code>1</code> <code>credible_threshold</code> <code>Optional[float]</code> <p>Credible threshold, by default None</p> <code>None</code> <code>credible_method</code> <code>Optional[str]</code> <p>Credible method, by default None</p> <code>None</code> <code>use_ref_EAF</code> <code>bool</code> <p>Use reference EAF, by default False</p> <code>False</code> <code>outfile</code> <code>Optional[str]</code> <p>Output file, by default None</p> <code>None</code> <code>threads</code> <code>int</code> <p>Number of threads, by default 1</p> <code>1</code> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def finemap_all_loci(\n    self,\n    sumstats: pd.DataFrame,\n    loci: pd.DataFrame,\n    lead_snps: pd.DataFrame,\n    methods: List[str],\n    var_prior: float = 0.2,\n    conditional: bool = False,\n    prior_file: Optional[str] = None,\n    sample_size: Optional[int] = None,\n    ldref: Optional[str] = None,\n    cond_snps_wind_kb: int = 1000,\n    max_causal: int = 1,\n    credible_threshold: Optional[float] = None,\n    credible_method: Optional[str] = None,\n    use_ref_EAF: bool = False,\n    outfile: Optional[str] = None,\n    threads: int = 1,\n):\n\"\"\"\n    Perform finemapping for all loci.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    loci : pd.DataFrame\n        Loci.\n    lead_snps : pd.DataFrame\n        Lead SNPs.\n    methods : List[str]\n        Finemapping methods.\n    var_prior : float, optional\n        Variance prior, by default 0.2\n    conditional : bool, optional\n        Conditional finemapping, by default False\n    prior_file : Optional[str], optional\n        Path to prior file, by default None\n    sample_size : Optional[int], optional\n        Sample size, by default None\n    ldref : Optional[str], optional\n        LD reference, by default None\n    cond_snps_wind_kb : int, optional\n        Conditional SNPs window, by default 1000\n    max_causal : int, optional\n        Maximum number of causal variants, by default 1\n    credible_threshold : Optional[float], optional\n        Credible threshold, by default None\n    credible_method : Optional[str], optional\n        Credible method, by default None\n    use_ref_EAF : bool, optional\n        Use reference EAF, by default False\n    outfile : Optional[str], optional\n        Output file, by default None\n    threads : int, optional\n        Number of threads, by default 1\n    \"\"\"\n    # sumstats = sg.make_SNPID_unique(sumstats, ColName.CHR, ColName.BP, ColName.EA, ColName.NEA)\n    if (\n        credible_threshold\n        and credible_method is None\n        and methods != [\"all\"]\n        and len(methods) == 1\n    ):\n        credible_method = methods[0]\n    kwargs_list = []\n    for chrom, start, end, lead_snp in loci[\n        [ColName.CHR, ColName.START, ColName.END, ColName.LEAD_SNP]\n    ].values:\n        kwargs = {\n            \"sumstats\": sumstats,\n            \"chrom\": chrom,\n            \"start\": start,\n            \"end\": end,\n            \"lead_snp\": lead_snp,\n            \"lead_snps\": lead_snps,\n            \"methods\": methods,\n            \"var_prior\": var_prior,\n            \"conditional\": conditional,\n            \"prior_file\": prior_file,\n            \"sample_size\": sample_size,\n            \"ldref\": ldref.format(chrom=chrom) if ldref else None,\n            \"cond_snps_wind_kb\": cond_snps_wind_kb,\n            \"max_causal\": max_causal,\n            \"credible_threshold\": credible_threshold,\n            \"credible_method\": credible_method,\n            \"use_ref_EAF\": use_ref_EAF,\n        }\n        kwargs_list.append(kwargs)\n    ef = EasyFinemap()\n    # output = []\n    # with Progress(\n    #     TextColumn(\"{task.description}\"),\n    #     BarColumn(),\n    #     MofNCompleteColumn(),\n    #     TimeElapsedColumn(),\n    #     auto_refresh=True,\n    # ) as progress:\n    #     with Pool(threads) as p:\n    #         task = progress.add_task(\"Perform Fine-mapping...\", total=len(loci))\n    #         results = [p.apply_async(ef.finemap_locus, kwds=kwargs) for kwargs in kwargs_list]\n    #         for res in results:\n    #             progress.update(task, advance=1)\n    #             progress.refresh()\n    #             output.append(res.get())\n    # with ProcessPoolExecutor(max_workers=threads) as executor:\n    #     output = []\n    #     with Progress(\n    #         TextColumn(\"{task.description}\"),\n    #         BarColumn(),\n    #         MofNCompleteColumn(),\n    #         TimeElapsedColumn(),\n    #         auto_refresh=True,\n    #     ) as progress:\n    #         task = progress.add_task(\"Perform Fine-mapping...\", total=len(kwargs_list))\n    #         for _ in executor.map(ef.finemap_locus_parallel, kwargs_list):\n    #             progress.update(task, advance=1)\n    #             progress.refresh()\n    #             output.append(_)\n    # output_df = pd.concat(output, ignore_index=True)\n    with Pool(threads) as p:\n        output = []\n        for result in tqdm(\n            p.imap(ef.finemap_locus_parallel, kwargs_list),\n            total=len(kwargs_list),\n            position=0,\n            leave=True,\n            desc=\"Perform Fine-mapping...\",\n        ):\n            output.append(result)\n    output_df = pd.concat(output, ignore_index=True)\n    if outfile:\n        output_df.to_csv(outfile, sep=\"\\t\", index=False, float_format=\"%0.6g\")\n    else:\n        return output_df\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.finemap_locus","title":"<code>finemap_locus(sumstats, chrom, start, end, methods, lead_snp, conditional=False, prior_file=None, temp_dir=None, **kwargs)</code>","text":"<p>Finemap a locus.</p> <ol> <li>Check if LD is needed, abf does not need LD.</li> <li>If LD is needed, intersect the locus with the LD reference and make the LD matrix.</li> <li>Run the finemapping method.</li> <li>Get the finemapping results.</li> <li>Merge the finemapping results with the input sumstats.</li> <li>Return the credible set or full summary statistics with posterior probabilities.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>methods</code> <code>List[str]</code> <p>Finemapping methods.</p> required <code>lead_snp</code> <code>str</code> <p>Lead SNP.</p> required <code>conditional</code> <code>bool</code> <p>Conditional finemapping, by default False</p> <code>False</code> <code>temp_dir</code> <code>Optional[str]</code> <p>Temporary directory, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Finemapping results.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>@io_in_tempdir('./tmp/easyfinemap')\ndef finemap_locus(\n    self,\n    sumstats: pd.DataFrame,\n    chrom: str,\n    start: int,\n    end: int,\n    methods: List[str],\n    lead_snp: str,\n    conditional: bool = False,\n    prior_file: Optional[str] = None,\n    temp_dir: Optional[str] = None,\n    **kwargs,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Finemap a locus.\n\n    1. Check if LD is needed, abf does not need LD.\n    2. If LD is needed, intersect the locus with the LD reference and make the LD matrix.\n    3. Run the finemapping method.\n    4. Get the finemapping results.\n    5. Merge the finemapping results with the input sumstats.\n    6. Return the credible set or full summary statistics with posterior probabilities.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    methods : List[str]\n        Finemapping methods.\n    lead_snp : str\n        Lead SNP.\n    conditional : bool, optional\n        Conditional finemapping, by default False\n    temp_dir : Optional[str], optional\n        Temporary directory, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        Finemapping results.\n    \"\"\"\n    locus_sumstats = sg.export_sumstats(sumstats, chrom, start, end)\n    locus_sumstats = sg.make_SNPID_unique(\n        locus_sumstats, ColName.CHR, ColName.BP, ColName.EA, ColName.NEA\n    )\n    locus_sumstats = locus_sumstats.replace(np.inf, 100)\n    locus_sumstats = locus_sumstats.replace(-np.inf, -100)\n    self.logger.info(f\"Finemap {chrom}:{start}-{end}\")\n    self.logger.info(f\"Number of SNPs: {locus_sumstats.shape[0]}\")\n    if len(locus_sumstats) &gt; 5000:\n        self.logger.warning(\n            \"The number of SNPs is greater than 5000, reduce the number of SNPs to 5000\"\n        )\n        locus_sumstats = locus_sumstats[\n            locus_sumstats[ColName.P] &lt; locus_sumstats[ColName.P].nsmallest(5000).iloc[-1]\n        ].copy()\n    if conditional:\n        cond_res = self.cond_sumstat(sumstats=locus_sumstats, lead_snp=lead_snp, **kwargs)\n        fm_input = cond_res.copy()\n        fm_input[ColName.BETA] = cond_res[ColName.COJO_BETA]\n        fm_input[ColName.SE] = cond_res[ColName.COJO_SE]\n        fm_input[ColName.P] = cond_res[ColName.COJO_P]\n        out_sumstats = locus_sumstats.merge(\n            cond_res[[ColName.SNPID, ColName.COJO_BETA, ColName.COJO_SE, ColName.COJO_P]],\n            on=ColName.SNPID,\n            how=\"left\",\n        )\n        max_causal = kwargs.get(\"max_causal\", 1)\n        if max_causal &gt; 1:\n            self.logger.warning(\n                \"Conditional finemapping does not support multiple causal variants\"\n            )\n    else:\n        fm_input = locus_sumstats.copy()\n        out_sumstats = locus_sumstats.copy()\n\n    allowed_methods = [\n        \"abf\",\n        \"finemap\",\n        \"paintor\",\n        \"caviarbf\",\n        \"susie\",\n        \"polyfun_finemap\",\n        \"polyfun_susie\",\n    ]\n    methods_required_ld = [\n        \"finemap\",\n        \"paintor\",\n        \"caviarbf\",\n        \"susie\",\n        \"polyfun_finemap\",\n        \"polyfun_susie\",\n    ]\n    if \"all\" in methods:\n        methods = allowed_methods\n    fm_input_ol = fm_input.copy()\n    if prior_file:\n        fm_input_ol = self.annotate_prior(fm_input_ol, prior_file)\n    if len(set(methods).intersection(set(methods_required_ld))) &gt; 0:\n        # TODO: reduce the number of SNPs when using paintor and caviarbf in multiple causal variant mode\n        ld_ol = self.prepare_ld_matrix(\n            sumstats=fm_input_ol, outprefix=f\"{temp_dir}/intersc\", **kwargs\n        )\n    # if os.path.exists(f\"{temp_dir}/intersc.ld\"):\n    #     fm_input_ol = ld_ol.copy()\n    for method in methods:\n        if method == \"abf\":\n            abf_pp = self.run_abf(sumstats=fm_input_ol, **kwargs)\n            out_sumstats[ColName.PP_ABF] = out_sumstats[ColName.SNPID].map(abf_pp)\n        elif method in methods_required_ld:\n            ld_matrix = f\"{temp_dir}/intersc.ld\"\n            if method == \"finemap\":\n                if os.path.exists(ld_matrix):\n                    finemap_pp = self.run_finemap(\n                        sumstats=ld_ol, ld_matrix=ld_matrix, prior_file=None, **kwargs\n                    )\n                    out_sumstats[ColName.PP_FINEMAP] = out_sumstats[ColName.SNPID].map(\n                        finemap_pp\n                    )\n                else:\n                    self.logger.warning(f\"LD matrix {ld_matrix} does not exist, skip {method}\")\n                    out_sumstats[ColName.PP_FINEMAP] = np.nan\n            elif method == \"paintor\":\n                if os.path.exists(ld_matrix):\n                    paintor_pp = self.run_paintor(sumstats=ld_ol, ld_matrix=ld_matrix, **kwargs)\n                    out_sumstats[ColName.PP_PAINTOR] = out_sumstats[ColName.SNPID].map(\n                        paintor_pp\n                    )\n                else:\n                    self.logger.warning(f\"LD matrix {ld_matrix} does not exist, skip {method}\")\n                    out_sumstats[ColName.PP_PAINTOR] = np.nan\n            elif method == \"caviarbf\":\n                if os.path.exists(ld_matrix):\n                    caviarbf_pp = self.run_caviarbf(\n                        sumstats=ld_ol, ld_matrix=ld_matrix, **kwargs\n                    )\n                    out_sumstats[ColName.PP_CAVIARBF] = out_sumstats[ColName.SNPID].map(\n                        caviarbf_pp\n                    )\n                else:\n                    self.logger.warning(f\"LD matrix {ld_matrix} does not exist, skip {method}\")\n                    out_sumstats[ColName.PP_CAVIARBF] = np.nan\n            elif method == \"susie\":\n                if os.path.exists(ld_matrix):\n                    susie_pp = self.run_susie(\n                        sumstats=ld_ol, ld_matrix=ld_matrix, prior_file=None, **kwargs\n                    )\n                    out_sumstats[ColName.PP_SUSIE] = out_sumstats[ColName.SNPID].map(susie_pp)\n                else:\n                    self.logger.warning(f\"LD matrix {ld_matrix} does not exist, skip {method}\")\n                    out_sumstats[ColName.PP_SUSIE] = np.nan\n            elif method == \"polyfun_finemap\":\n                if os.path.exists(ld_matrix):\n                    polyfun_finemap_pp = self.run_finemap(\n                        sumstats=ld_ol, ld_matrix=ld_matrix, prior_file=prior_file, **kwargs\n                    )\n                    out_sumstats[ColName.PP_POLYFUN_FINEMAP] = out_sumstats[ColName.SNPID].map(\n                        polyfun_finemap_pp\n                    )\n                else:\n                    self.logger.warning(f\"LD matrix {ld_matrix} does not exist, skip {method}\")\n                    out_sumstats[ColName.PP_POLYFUN_FINEMAP] = np.nan\n            elif method == \"polyfun_susie\":\n                if os.path.exists(ld_matrix):\n                    polyfun_susie_pp = self.run_susie(\n                        sumstats=ld_ol, ld_matrix=ld_matrix, prior_file=prior_file, **kwargs\n                    )\n                    out_sumstats[ColName.PP_POLYFUN_SUSIE] = out_sumstats[ColName.SNPID].map(\n                        polyfun_susie_pp\n                    )\n                else:\n                    self.logger.warning(f\"LD matrix {ld_matrix} does not exist, skip {method}\")\n                    out_sumstats[ColName.PP_POLYFUN_SUSIE] = np.nan\n        else:\n            raise ValueError(f\"Method {method} is not supported\")\n\n    credible_set = self.get_credset(finemap_res=out_sumstats, **kwargs)\n    credible_set[ColName.LEAD_SNP] = lead_snp\n    return credible_set\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.finemap_locus_parallel","title":"<code>finemap_locus_parallel(kwargs)</code>","text":"<p>Perform finemapping for a locus in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>dict</code> <p>Keyword arguments.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Finemapping results.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def finemap_locus_parallel(self, kwargs):\n\"\"\"\n    Perform finemapping for a locus in parallel.\n\n    Parameters\n    ----------\n    kwargs : dict\n        Keyword arguments.\n\n    Returns\n    -------\n    pd.DataFrame\n        Finemapping results.\n    \"\"\"\n    return self.finemap_locus(**kwargs)\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.get_credset","title":"<code>get_credset(finemap_res, max_causal, credible_threshold=None, credible_method=None, **kwargs)</code>","text":"<p>Get credible set.</p> <p>Parameters:</p> Name Type Description Default <code>finemap_res</code> <code>DataFrame</code> <p>Finemap results.</p> required <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants.</p> required <code>credible_threshold</code> <code>Optional[float]</code> <p>Credible threshold, by default None</p> <code>None</code> <code>credible_method</code> <code>Optional[str]</code> <p>Credible set method, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Credible set.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def get_credset(\n    self,\n    finemap_res: pd.DataFrame,\n    max_causal: int,\n    credible_threshold: Optional[float] = None,\n    credible_method: Optional[str] = None,\n    **kwargs,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Get credible set.\n\n    Parameters\n    ----------\n    finemap_res : pd.DataFrame\n        Finemap results.\n    max_causal : int\n        Maximum number of causal variants.\n    credible_threshold : Optional[float], optional\n        Credible threshold, by default None\n    credible_method : Optional[str], optional\n        Credible set method, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        Credible set.\n    \"\"\"\n    if credible_threshold is None:\n        return finemap_res\n    else:\n        credible_threshold = credible_threshold * max_causal\n        if credible_method:\n            pp_col = f\"PP_{credible_method.upper()}\"\n            credible_set = finemap_res.sort_values(pp_col, ascending=False)\n            credible_set = finemap_res.sort_values(by=pp_col, ascending=False)\n            credible_set = credible_set[\n                credible_set[pp_col].shift().fillna(0).cumsum() &lt;= credible_threshold\n            ]\n        else:\n            raise ValueError(\n                \"Must specify credible set method when credible threshold is specified\"\n            )\n    return credible_set.reset_index(drop=True)\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.prepare_ld_matrix","title":"<code>prepare_ld_matrix(sumstats, ldref, outprefix, use_ref_EAF=False, **kwargs)</code>","text":"<p>Prepare LD matrix.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>ldref</code> <code>str</code> <p>Path to LD reference.</p> required <code>outprefix</code> <code>str</code> <p>Output prefix.</p> required <code>use_ref_EAF</code> <code>bool</code> <p>Use reference EAF, by default False</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>LD matrix.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def prepare_ld_matrix(\n    self,\n    sumstats: pd.DataFrame,\n    ldref: str,\n    outprefix: str,\n    use_ref_EAF: bool = False,\n    **kwargs,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Prepare LD matrix.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    ldref : str\n        Path to LD reference.\n    outprefix : str\n        Output prefix.\n    use_ref_EAF : bool, optional\n        Use reference EAF, by default False\n\n    Returns\n    -------\n    pd.DataFrame\n        LD matrix.\n    \"\"\"\n    if ldref is None:\n        raise ValueError(\"LD reference is required for LD-based finemapping\")\n    ld = LDRef()\n    sumstats_ol = ld.intersect(sumstats, ldref, outprefix, use_ref_EAF)\n    ld.make_ld(outprefix, outprefix)\n    return sumstats_ol\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.run_abf","title":"<code>run_abf(sumstats, var_prior=0.2, max_causal=1, **kwargs)</code>","text":"<p>Run ABF.</p> <p>calculate the approximate Bayes factor (ABF) from BETA and SE, using the formula: SNP_BF = sqrt(SE/(SE + W^2))EXP(W^2/(SE + W^2)*(BETA^2/SE^2)/2) where W is variance prior, usually set to 0.15 for quantitative traits and 0.2 for binary traits. the posterior probability of each variant being causal is calculated using the formula: PP(causal) = SNP_BF / sum(all_SNP_BFs)</p> <p>Reference: Asimit, J. L. et al. Eur J Hum Genet (2016)</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>var_prior</code> <code>float</code> <p>Variance prior, by default 0.2, usually set to 0.15 for quantitative traits and 0.2 for binary traits.</p> <code>0.2</code> <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants, by default 1</p> <code>1</code> <p>Returns:</p> Type Description <code>Series</code> <p>The result of ABF.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def run_abf(\n    self, sumstats: pd.DataFrame, var_prior: float = 0.2, max_causal: int = 1, **kwargs\n) -&gt; pd.Series:\n\"\"\"\n    Run ABF.\n\n    calculate the approximate Bayes factor (ABF) from BETA and SE, using the\n    formula:\n    SNP_BF = sqrt(SE/(SE + W^2))EXP(W^2/(SE + W^2)*(BETA^2/SE^2)/2)\n    where W is variance prior, usually set to 0.15 for quantitative traits\n    and 0.2 for binary traits.\n    the posterior probability of each variant being causal is calculated\n    using the formula:\n    PP(causal) = SNP_BF / sum(all_SNP_BFs)\n\n    Reference: Asimit, J. L. et al. Eur J Hum Genet (2016)\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    var_prior : float, optional\n        Variance prior, by default 0.2, usually set to 0.15 for quantitative traits\n        and 0.2 for binary traits.\n    max_causal : int, optional\n        Maximum number of causal variants, by default 1\n\n    Returns\n    -------\n    pd.Series\n        The result of ABF.\n    \"\"\"\n    if max_causal &gt; 1:\n        raise NotImplementedError(\"ABF only support single causal variant.\")\n    df = sumstats.copy()\n    df[\"W2\"] = var_prior**2\n    df[\"SNP_BF\"] = np.sqrt((df[ColName.SE] ** 2 / (df[ColName.SE] ** 2 + df[\"W2\"]))) * np.exp(\n        df[\"W2\"]\n        / (df[ColName.BETA] ** 2 + df[\"W2\"])\n        * (df[ColName.BETA] ** 2 / df[ColName.SE] ** 2)\n        / 2\n    )\n    df[ColName.PP_ABF] = df[\"SNP_BF\"] / df[\"SNP_BF\"].sum()\n    return pd.Series(data=df[ColName.PP_ABF].values, index=df[ColName.SNPID].tolist())\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.run_caviarbf","title":"<code>run_caviarbf(sumstats, ld_matrix, max_causal=1, temp_dir=None, **kwargs)</code>","text":"<p>Run CAVIAR-BF.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>ld_matrix</code> <code>str</code> <p>Path to LD matrix.</p> required <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants, by default 1</p> <code>1</code> <code>temp_dir</code> <code>Optional[str]</code> <p>Path to tempdir, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>The result of CAVIAR-BF.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>@io_in_tempdir('./tmp/easyfinemap')\ndef run_caviarbf(\n    self,\n    sumstats: pd.DataFrame,\n    ld_matrix: str,\n    max_causal: int = 1,\n    temp_dir: Optional[str] = None,\n    **kwargs,\n):\n\"\"\"\n    Run CAVIAR-BF.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    ld_matrix : str\n        Path to LD matrix.\n    max_causal : int, optional\n        Maximum number of causal variants, by default 1\n    temp_dir : Optional[str], optional\n        Path to tempdir, by default None\n\n    Returns\n    -------\n    pd.Series\n        The result of CAVIAR-BF.\n    \"\"\"\n    caviar_input = sumstats.copy()\n    caviar_input[ColName.Z] = caviar_input[ColName.BETA] / caviar_input[ColName.SE]\n    caviar_input[[ColName.SNPID, ColName.Z]].to_csv(\n        f\"{temp_dir}/caviar.input\", sep=\" \", index=False, header=False\n    )\n    n_variants = caviar_input.shape[0]\n    cmd = [\n        self.caviarbf,\n        \"-z\",\n        f\"{temp_dir}/caviar.input\",\n        \"-r\",\n        ld_matrix,\n        \"-t\",\n        \"0\",\n        \"-a\",\n        \"0.1281429\",\n        \"-n\",\n        str(n_variants),\n        \"-c\",\n        str(max_causal),\n        \"-o\",\n        f\"{temp_dir}/caviar.output\",\n    ]\n    self.logger.debug(f\"run CAVIAR-BF: {' '.join(cmd)}\")\n    run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    cmd = [\n        self.model_search,\n        \"-i\",\n        f\"{temp_dir}/caviar.output\",\n        \"-m\",\n        str(n_variants),\n        \"-p\",\n        \"0\",\n        \"-o\",\n        f\"{temp_dir}/caviar.prior0\",\n    ]\n    self.logger.debug(f\"run CAVIAR-BF: {' '.join(cmd)}\")\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        raise RuntimeError(res.stderr)\n    else:\n        caviar_res = pd.read_csv(f\"{temp_dir}/caviar.prior0.marginal\", sep=\" \", header=None)\n        caviar_res.sort_values(by=0, inplace=True)  # type: ignore\n        caviar_res = pd.Series(caviar_res[1].values, index=caviar_input[ColName.SNPID].tolist())\n        return caviar_res\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.run_finemap","title":"<code>run_finemap(sumstats, ld_matrix, sample_size, max_causal=1, prior_file=None, temp_dir=None, **kwargs)</code>","text":"<p>Run FINEMAP.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>ld_matrix</code> <code>str</code> <p>Path to LD matrix.</p> required <code>sample_size</code> <code>int</code> <p>Sample size.</p> required <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants, by default 1</p> <code>1</code> <code>prior_file</code> <code>Optional[str]</code> <p>Path to prior file, by default None</p> <code>None</code> <code>temp_dir</code> <code>Optional[str]</code> <p>Path to tempdir, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>The result of FINEMAP.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>@io_in_tempdir('./tmp/easyfinemap')\ndef run_finemap(\n    self,\n    sumstats: pd.DataFrame,\n    ld_matrix: str,\n    sample_size: int,\n    max_causal: int = 1,\n    prior_file: Optional[str] = None,\n    temp_dir: Optional[str] = None,\n    **kwargs,\n) -&gt; pd.Series:\n\"\"\"\n    Run FINEMAP.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    ld_matrix : str\n        Path to LD matrix.\n    sample_size : int\n        Sample size.\n    max_causal : int, optional\n        Maximum number of causal variants, by default 1\n    prior_file : Optional[str], optional\n        Path to prior file, by default None\n    temp_dir : Optional[str], optional\n        Path to tempdir, by default None\n\n    Returns\n    -------\n    pd.Series\n        The result of FINEMAP.\n    \"\"\"\n    if ColName.MAF not in sumstats.columns:\n        raise ValueError(f\"{ColName.MAF} is required for FINEMAP.\")\n    finemap_input = sumstats.copy()\n    finemap_input[ColName.MAF] = finemap_input[ColName.MAF].replace(0, 0.00001)\n    if prior_file:\n        finemap_input = finemap_input[\n            [\n                ColName.SNPID,\n                ColName.CHR,\n                ColName.BP,\n                ColName.EA,\n                ColName.NEA,\n                ColName.MAF,\n                ColName.BETA,\n                ColName.SE,\n                'SNPVAR',\n            ]\n        ]\n        finemap_input.rename(\n            columns={\n                ColName.SNPID: \"rsid\",\n                ColName.CHR: \"chromosome\",\n                ColName.BP: \"position\",\n                ColName.MAF: \"maf\",\n                ColName.BETA: \"beta\",\n                ColName.SE: \"se\",\n                ColName.EA: \"allele1\",\n                ColName.NEA: \"allele2\",\n                'SNPVAR': 'prob',\n            },\n            inplace=True,\n        )\n        finemap_input['prob'] = finemap_input['prob'] / finemap_input['prob'].sum()\n    else:\n        finemap_input = finemap_input[\n            [\n                ColName.SNPID,\n                ColName.CHR,\n                ColName.BP,\n                ColName.EA,\n                ColName.NEA,\n                ColName.MAF,\n                ColName.BETA,\n                ColName.SE,\n            ]\n        ]\n        finemap_input.rename(\n            columns={\n                ColName.SNPID: \"rsid\",\n                ColName.CHR: \"chromosome\",\n                ColName.BP: \"position\",\n                ColName.MAF: \"maf\",\n                ColName.BETA: \"beta\",\n                ColName.SE: \"se\",\n                ColName.EA: \"allele1\",\n                ColName.NEA: \"allele2\",\n            },\n            inplace=True,\n        )\n    finemap_input.to_csv(f\"{temp_dir}/finemap.z\", sep=\" \", index=False, float_format=\"%0.5f\")\n    with open(f\"{temp_dir}/finemap.master\", \"w\") as f:\n        master_content = [\n            f\"{temp_dir}/finemap.z\",\n            ld_matrix,\n            f\"{temp_dir}/finemap.snp\",\n            f\"{temp_dir}/finemap.config\",\n            f\"{temp_dir}/finemap.cred\",\n            f\"{temp_dir}/finemap.log\",\n            str(sample_size),\n        ]\n        f.write(\"z;ld;snp;config;cred;log;n_samples\\n\")\n        f.write(\";\".join(master_content))\n    cmd = [\n        self.finemap,\n        \"--sss\",\n        \"--in-files\",\n        f\"{temp_dir}/finemap.master\",\n        \"--n-causal-snps\",\n        str(max_causal),\n        \"--prior-snps\" if prior_file else \"\",\n    ]\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    self.logger.debug(f\"run FINEMAP: {' '.join(cmd)}\")\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        raise RuntimeError(res.stderr)\n    else:\n        if os.path.getsize(f\"{temp_dir}/finemap.snp\") == 0:\n            self.logger.warning(\"FINEMAP output is empty.\")\n            return pd.Series(index=finemap_input[\"rsid\"].values)\n        else:\n            finemap_res = pd.read_csv(f\"{temp_dir}/finemap.snp\", sep=\" \", usecols=[\"rsid\", \"prob\"])\n            finemap_res = pd.Series(finemap_res[\"prob\"].values, index=finemap_res[\"rsid\"].values)  # type: ignore\n            return finemap_res\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.run_paintor","title":"<code>run_paintor(sumstats, ld_matrix, max_causal=1, temp_dir=None, **kwargs)</code>","text":"<p>Run PAINTOR.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>ld_matrix</code> <code>str</code> <p>Path to LD matrix.</p> required <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants, by default 1</p> <code>1</code> <code>temp_dir</code> <code>Optional[str]</code> <p>Path to tempdir, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>The result of PAINTOR.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>@io_in_tempdir('./tmp/easyfinemap')\ndef run_paintor(\n    self,\n    sumstats: pd.DataFrame,\n    ld_matrix: str,\n    max_causal: int = 1,\n    temp_dir: Optional[str] = None,\n    **kwargs,\n):\n\"\"\"\n    Run PAINTOR.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    ld_matrix : str\n        Path to LD matrix.\n    max_causal : int, optional\n        Maximum number of causal variants, by default 1\n    temp_dir : Optional[str], optional\n        Path to tempdir, by default None\n\n    Returns\n    -------\n    pd.Series\n        The result of PAINTOR.\n    \"\"\"\n    paintor_input = sumstats.copy()\n    paintor_input[\"coding\"] = 1  # TODO: support paintor annotation mode\n    paintor_input[\"Zscore\"] = paintor_input[ColName.BETA] / paintor_input[ColName.SE]\n    input_prefix = \"paintor.processed\"\n    paintor_input[[ColName.SNPID, ColName.CHR, ColName.BP, \"Zscore\"]].to_csv(\n        f\"{temp_dir}/{input_prefix}\", sep=\" \", index=False\n    )\n    paintor_input[\"coding\"].to_csv(\n        f\"{temp_dir}/{input_prefix}.annotations\", sep=\" \", index=False, header=True\n    )\n    with open(f\"{temp_dir}/{input_prefix}.input\", \"w\") as f:\n        f.write(input_prefix)\n    ld_matrix_abs_path = os.path.abspath(ld_matrix)\n    run(\n        ['ln', \"-s\", ld_matrix_abs_path, f'{temp_dir}/{input_prefix}.ld'],\n        stdout=PIPE,\n        stderr=PIPE,\n        universal_newlines=True,\n    )\n    cmd = [\n        self.paintor,\n        \"-input\",\n        f\"{temp_dir}/{input_prefix}.input\",\n        \"-out\",\n        temp_dir,\n        \"-Zhead\",\n        \"Zscore\",\n        \"-LDname\",\n        \"ld\",\n        \"-enumerate\",\n        str(max_causal),\n        \"-in\",\n        temp_dir,\n    ]\n    self.logger.debug(f\"run PAINTOR: {' '.join(cmd)}\")\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        raise RuntimeError(res.stderr)\n    else:\n        paintor_res = pd.read_csv(\n            f\"{temp_dir}/paintor.processed.results\",\n            sep=\" \",\n            usecols=[\"SNPID\", \"Posterior_Prob\"],\n        )\n        paintor_res = pd.Series(\n            paintor_res[\"Posterior_Prob\"].values, index=paintor_res[\"SNPID\"].tolist()\n        )\n        return paintor_res\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.run_susie","title":"<code>run_susie(sumstats, ld_matrix, sample_size, max_causal=1, prior_file=None, temp_dir=None, **kwargs)</code>","text":"<p>Run SuSiE.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>ld_matrix</code> <code>str</code> <p>Path to LD matrix.</p> required <code>sample_size</code> <code>int</code> <p>Sample size.</p> required <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants, by default 1</p> <code>1</code> <code>prior_file</code> <code>Optional[str]</code> <p>Path to prior file, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>The result of SuSiE.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>@io_in_tempdir('./tmp/easyfinemap')\ndef run_susie(\n    self,\n    sumstats: pd.DataFrame,\n    ld_matrix: str,\n    sample_size: int,\n    max_causal: int = 1,\n    prior_file: Optional[str] = None,\n    temp_dir: Optional[str] = None,\n    **kwargs,\n) -&gt; pd.Series:\n\"\"\"\n    Run SuSiE.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    ld_matrix : str\n        Path to LD matrix.\n    sample_size : int\n        Sample size.\n    max_causal : int, optional\n        Maximum number of causal variants, by default 1\n    prior_file : Optional[str], optional\n        Path to prior file, by default None\n\n    Returns\n    -------\n    pd.Series\n        The result of SuSiE.\n    \"\"\"\n    susie_input = sumstats.copy()\n    susie_input[ColName.Z] = susie_input[ColName.BETA] / susie_input[ColName.SE]\n    if prior_file:\n        susie_input['SNPVAR'] = susie_input['SNPVAR'] / susie_input['SNPVAR'].sum()\n    else:\n        susie_input['SNPVAR'] = 1 / len(susie_input)\n    susie_input[[ColName.SNPID, ColName.Z, 'SNPVAR']].to_csv(\n        f\"{temp_dir}/susie.input\", sep=\" \", index=False, header=True\n    )\n    self.logger.debug(f\"run SuSiE: {temp_dir}/susie.input, prior_file: {prior_file}\")\n\n    import rpy2.robjects as ro\n    from rpy2.rinterface_lib.callbacks import logger as rpy2_logger\n\n    rpy2_logger.setLevel(logging.ERROR)\n\n    ro.r(\n        f'''library('data.table')\n            ld = fread('{ld_matrix}', sep=' ', header=FALSE)\n            ld = as.matrix(ld)\n            df = fread('{temp_dir}/susie.input', sep=' ', header=TRUE)\n            z = df$Z\n            prior = df$SNPVAR\n            library('susieR')\n            res = susie_rss(z, ld, n={sample_size}, L = {max_causal}, prior_weights = prior)\n            pip = res$pip'''\n    )\n    susie_input['pip'] = ro.r('pip')\n    susie_res = pd.Series(susie_input['pip'].values, index=susie_input[ColName.SNPID].tolist())\n    return susie_res\n</code></pre>"},{"location":"api/tools/","title":"Tools","text":"<p>check if tools are installed and return their path.</p> Source code in <code>easyfinemap/tools.py</code> <pre><code>def __init__(self):\n\"\"\"Initialize.\"\"\"\n    self.logger = logging.getLogger(\"Tools\")\n</code></pre>"},{"location":"api/tools/#easyfinemap.tools.Tools.bcftools","title":"<code>bcftools</code>  <code>property</code>","text":"<p>Check if bcftools is installed.</p>"},{"location":"api/tools/#easyfinemap.tools.Tools.caviarbf","title":"<code>caviarbf</code>  <code>property</code>","text":"<p>Check if caviarbf is installed.</p>"},{"location":"api/tools/#easyfinemap.tools.Tools.finemap","title":"<code>finemap</code>  <code>property</code>","text":"<p>Check if finemap is installed.</p>"},{"location":"api/tools/#easyfinemap.tools.Tools.gcta","title":"<code>gcta</code>  <code>property</code>","text":"<p>Check if gcta is installed.</p>"},{"location":"api/tools/#easyfinemap.tools.Tools.model_search","title":"<code>model_search</code>  <code>property</code>","text":"<p>Check if model_search is installed.</p>"},{"location":"api/tools/#easyfinemap.tools.Tools.paintor","title":"<code>paintor</code>  <code>property</code>","text":"<p>Check if paintor is installed.</p>"},{"location":"api/tools/#easyfinemap.tools.Tools.plink","title":"<code>plink</code>  <code>property</code>","text":"<p>Check if plink is installed.</p>"},{"location":"api/utils/","title":"utils","text":"<p>Utils for easyfinemap.</p>"},{"location":"api/utils/#easyfinemap.utils.get_significant_snps","title":"<code>get_significant_snps(df, pvalue_threshold=5e-08, use_most_sig_if_no_sig=True)</code>","text":"<p>Get the significant snps from the input file, filter by pvalue.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input summary statistics.</p> required <code>pvalue_threshold</code> <code>float</code> <p>The pvalue threshold, by default 5e-8</p> <code>5e-08</code> <code>use_most_sig_if_no_sig</code> <code>bool</code> <p>Whether to use the most significant SNP if no significant SNP found, by default True</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The significant snps, sorted by pvalue.</p> Source code in <code>easyfinemap/utils.py</code> <pre><code>def get_significant_snps(df: pd.DataFrame, pvalue_threshold: float = 5e-8, use_most_sig_if_no_sig: bool = True):\n\"\"\"\n    Get the significant snps from the input file, filter by pvalue.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The input summary statistics.\n    pvalue_threshold : float, optional\n        The pvalue threshold, by default 5e-8\n    use_most_sig_if_no_sig : bool, optional\n        Whether to use the most significant SNP if no significant SNP found, by default True\n\n    Returns\n    -------\n    pd.DataFrame\n        The significant snps, sorted by pvalue.\n    \"\"\"\n    sig_df = df.loc[df[ColName.P] &lt; pvalue_threshold].copy()\n    if sig_df.empty:\n        if use_most_sig_if_no_sig:\n            sig_df = df.loc[df[ColName.P] == df[ColName.P].min()].copy()\n            logging.debug(f\"Use the most significant SNP: {sig_df[ColName.SNPID].values[0]}\")\n            logging.debug(f\"pvalue: {sig_df[ColName.P].values[0]}\")\n        else:\n            raise ValueError(\"No significant SNPs found.\")\n    else:\n        sig_df.sort_values(ColName.P, inplace=True)\n        sig_df.reset_index(drop=True, inplace=True)\n    return sig_df\n</code></pre>"},{"location":"api/utils/#easyfinemap.utils.io_in_tempdir","title":"<code>io_in_tempdir(dir='./tmp')</code>","text":"<p>Make tempdir for process.</p> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str</code> <p>The tempdir, by default './tmp'</p> <code>'./tmp'</code> <p>Returns:</p> Type Description <code>decorator</code> <p>The decorator of io in tempdir.</p> Source code in <code>easyfinemap/utils.py</code> <pre><code>def io_in_tempdir(dir='./tmp'):\n\"\"\"\n    Make tempdir for process.\n\n    Parameters\n    ----------\n    dir : str, optional\n        The tempdir, by default './tmp'\n\n    Returns\n    -------\n    decorator\n        The decorator of io in tempdir.\n    \"\"\"\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            temp_dir = tempfile.mkdtemp(dir=dir)\n            logger = logging.getLogger(\"IO\")\n            logger.debug(f\"Tempdir: {temp_dir}\")\n            try:\n                result = func(*args, temp_dir=temp_dir, **kwargs)\n            except Exception:\n                raise\n            else:\n                if logging.getLogger().getEffectiveLevel() &gt;= logging.INFO:\n                    shutil.rmtree(temp_dir)\n                pass\n            return result  # type: ignore\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"api/utils/#easyfinemap.utils.make_SNPID_unique","title":"<code>make_SNPID_unique(sumstat, replace_rsIDcol=False, remove_duplicates=True)</code>","text":"<p>Make the SNPID unique.</p> <p>The unique SNPID is chr-bp-sorted(EA,NEA)</p> <p>Parameters:</p> Name Type Description Default <code>sumstat</code> <code>DataFrame</code> <p>The input summary statistics.</p> required <code>replace_rsIDcol</code> <code>bool</code> <p>Whether to replace the rsID column with the unique SNPID, by default False</p> <code>False</code> <code>remove_duplicates</code> <code>bool</code> <p>Whether to remove the duplicated SNPs, keep the one with smallest P-value, by default True</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The summary statistics with unique SNPID.</p> Source code in <code>easyfinemap/utils.py</code> <pre><code>def make_SNPID_unique(sumstat: pd.DataFrame, replace_rsIDcol: bool = False, remove_duplicates: bool = True):\n\"\"\"\n    Make the SNPID unique.\n\n    The unique SNPID is chr-bp-sorted(EA,NEA)\n\n    Parameters\n    ----------\n    sumstat : pd.DataFrame\n        The input summary statistics.\n    replace_rsIDcol : bool, optional\n        Whether to replace the rsID column with the unique SNPID, by default False\n    remove_duplicates : bool, optional\n        Whether to remove the duplicated SNPs, keep the one with smallest P-value, by default True\n\n    Returns\n    -------\n    pd.DataFrame\n        The summary statistics with unique SNPID.\n    \"\"\"\n    df = sumstat.copy()\n    allele_df = df[[ColName.EA, ColName.NEA]].copy()\n    b = allele_df.values\n    b.sort(axis=1)\n    allele_df[[ColName.EA, ColName.NEA]] = b\n    allele_df[ColName.SNPID] = (\n        df[ColName.CHR].astype(str)\n        + \"-\"\n        + df[ColName.BP].astype(str)\n        + \"-\"\n        + allele_df[ColName.EA]\n        + \"-\"\n        + allele_df[ColName.NEA]\n    )\n    if replace_rsIDcol:\n        df[ColName.RSID] = allele_df[ColName.SNPID]\n    else:\n        if ColName.SNPID in df.columns:\n            df.drop(ColName.SNPID, axis=1, inplace=True)\n        df.insert(loc=0, column=ColName.SNPID, value=allele_df[ColName.SNPID].values)  # type: ignore\n    if remove_duplicates:\n        df.sort_values(ColName.P, inplace=True)\n        if replace_rsIDcol:\n            df.drop_duplicates(subset=[ColName.RSID], keep=\"first\", inplace=True)\n        else:\n            df.drop_duplicates(subset=[ColName.SNPID], keep=\"first\", inplace=True)\n        df.sort_values([ColName.CHR, ColName.BP], inplace=True)\n        df.reset_index(drop=True, inplace=True)\n    return df\n</code></pre>"}]}